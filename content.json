{"meta":{"title":"Star","subtitle":null,"description":"一闪一闪亮晶晶，漫天都是小星星~","author":"Star","url":"https://xingxin-99.github.io"},"pages":[{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"bangumi/index.html","permalink":"https://xingxin-99.github.io/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"about","date":"2018-12-12T14:14:36.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"about/index.html","permalink":"https://xingxin-99.github.io/about/index.html","excerpt":"","text":"[さくら荘のhojun] 与&nbsp; Mashiro&nbsp; （ 真（ま）白（しろ） ） 对话中... bot_ui_ini()","keywords":"关于"},{"title":"Ca","date":"2018-12-12T14:14:16.000Z","updated":"2023-08-25T05:38:52.619Z","comments":true,"path":"categories/index.html","permalink":"https://xingxin-99.github.io/categories/index.html","excerpt":"","text":""},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"client/index.html","permalink":"https://xingxin-99.github.io/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"comment","date":"2018-12-20T15:13:48.000Z","updated":"2021-11-09T14:13:18.000Z","comments":true,"path":"comment/index.html","permalink":"https://xingxin-99.github.io/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","keywords":"留言板"},{"title":"donate","date":"2018-12-20T15:13:05.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"donate/index.html","permalink":"https://xingxin-99.github.io/donate/index.html","excerpt":"","text":"","keywords":"谢谢饲主了喵~"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"lab/index.html","permalink":"https://xingxin-99.github.io/lab/index.html","excerpt":"","text":"sakura主题balabala","keywords":"Lab实验室"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2021-11-09T14:13:18.000Z","comments":true,"path":"links/index.html","permalink":"https://xingxin-99.github.io/links/index.html","excerpt":"","text":"","keywords":"友人帐"},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"music/index.html","permalink":"https://xingxin-99.github.io/music/index.html","excerpt":"","text":"","keywords":"喜欢的音乐"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2021-11-09T14:13:18.000Z","comments":true,"path":"rss/index.html","permalink":"https://xingxin-99.github.io/rss/index.html","excerpt":"","text":""},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"theme-sakura/index.html","permalink":"https://xingxin-99.github.io/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro","keywords":"Hexo 主题 Sakura 🌸"},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2021-11-09T14:13:18.000Z","comments":true,"path":"tags/index.html","permalink":"https://xingxin-99.github.io/tags/index.html","excerpt":"","text":""},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2021-11-09T14:13:18.000Z","comments":false,"path":"video/index.html","permalink":"https://xingxin-99.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"}],"posts":[{"title":"测试","slug":"测试-1","date":"2023-08-27T08:18:42.000Z","updated":"2023-08-27T08:33:26.794Z","comments":true,"path":"2023/08/27/测试-1/","link":"","permalink":"https://xingxin-99.github.io/2023/08/27/测试-1/","excerpt":"","text":"table { table-layout: fixed; width: 1000px; /*表格宽度*/ max-width: 1000px; /*表格最大宽度，避免表格过宽*/ border: 1px solid #dedede; /*表格外边框设置*/ margin: 15px auto; /*外边距*/ border-collapse: collapse; /*使用单一线条的边框*/ word-break:break-all; word-wrap:break-word; empty-cells: show; /*单元格无内容依旧绘制边框*/ } table th, table td { height: 35px; /*统一每一行的默认高度*/ border: 1px solid #dedede; /*内部边框样式*/ padding: 0 10px; /*内边距*/ } table th { font-weight: bold; /*加粗*/ text-align: center !important; /*内容居中，加上 !important 避免被 Markdown 样式覆盖*/ background: rgba(158,188,226,0.2); /*背景色*/ } table tbody tr:nth-child(2n) { background: rgba(158,188,226,0.12); } table th { white-space: nowrap; /*表头内容强制在一行显示*/ } table th:nth-of-type(1){ width: 20%; } table th:nth-of-type(2){ width: 20%; } table th:nth-of-type(3){ width: 20%; } table th:nth-of-type(4){ width: 40%; } 测试基础什么是软件测试？ 复习时间 2023/8/6 2023/8/16 使用某些技术手段对软件进行操作，发现软件缺陷，判断软件是否满足使用需求 什么是黑盒测试？ 复习时间 2023/8/4 2023/8/16 黑盒测试是指在进行测试时，我们看不见程序的源代码，只对程序的功能进行测试。在测试的过程中主要关注输入与输出以及输出是否符合预期。其中功能测试又可称为黑盒测试 什么是白盒测试？ 复习时间 2023/8/4 2023/8/16 白盒测试是指测试的过程中能看到程序的源代码，主要是对程序的源代码进行测试。测试者检查程序的内部结构，根据内部逻辑来设计测试用例。比如单元测试就是一种白盒测试。白盒测试根据软件的内部逻辑设计测试用例，常用的技术是逻辑覆盖，即考察用测试数据运行被测程序时对程序逻辑的覆盖程度。主要的覆盖标准有 6 种：语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、组合条件覆盖和路径覆盖。 什么是灰盒测试？（集成测试、接口测试） 复习时间 2023/8/4 2023/8/16 灰盒测试是介于白盒测试和黑盒测试之间的一种测试方法，它能看见程序的部分源码，主要是对程序的接口进行测试。在我们执行测试的过程中，一般是先进行单元测试，再进行集成测试，最后进行系统测试。在我们测试完成单个模块运行正确之后，还需要去验证单个模块与模块组合在一起时是否会出现问题，这个方式就是灰盒测试。 为什么进行了白盒测试之后还要进行黑盒测试？ 复习时间 2023/8/4 2023/8/16 白盒测试不仅仅关注输入与输出的结果是否正确，同时还关注程序是如何处理的。而黑盒测试在整个测试过程中只关注输入和输出，如果输入一个测试数据，输出的结果是正确的，我们就认为这个功能是正确的。虽然从某种角度来看，白盒测试比黑盒测试更为全面。但是有一些黑盒测试的内容是白盒测试不能做到的。比如黑盒测试是更接近于用户使用的测试，因此我们还会关注程序的易用性、界面展示、业务流程等，而白盒测试时并不考虑这些。 测试的基本流程 复习时间 2023/8/16 需求分析 阅读需求文档，联合前端、后端、测试、产品等部门，确保各部门对需求理解一致；了解软件的具体功能 计划编写 确定测试的目标、范围对人力、物力进行分配，确定那些人要具体做哪些事情，对进度进行安排确定要使用哪些测试工具、测试策略 用例设计 分析需求，从需求中提取测试点，来设计测试用例 用例执行，提交bug，回归测试 当进行测试后，会发现软件的缺陷。确定缺陷后，将缺陷提交给开发人员，开发人员修改后进行回归测试 测试报告 常见的黑盒测试方法有哪些？| 复习时间 | 2023/8/4 | 2023/8/16 || — | — | — | 等价类划分法（穷举场景） 指在所有的测试数据中，对具有某种共同特征的数据集合进行划分，然后从每一个子集中选取少数具有代表性的数据作为测试用例。举例：验证6-10位自然数QQ号的合法性按照等价类划分法：有效等价类：6-10位自然数；无效等价类：&lt;6位，&gt;10位自然数，以及6-10位非自然数 边界值分析（有边界范围） 对输入、输出的边界值进行测试。在边界值分析法中规范了要选择的边界值，上点、离点、内点 因果图分析 利用图解法分析输入的各种组合情况，从而设计测试用例的方法 判定表法（多条件依赖关系） 以表格形式表达多条件依赖逻辑判断的工具判定表由条件桩、动作桩、条件项、动作项组成，根据条件项确定动作项，贯穿条件项和动作项的一列是一条规则 错误推测法 根据测试者以往测试经验来对可能出现错误的地方进行测试。 为什么要进行自动化测试？ 复习时间 2023/8/16 自动化测试是指使用自动化测试工具来执行测试用例，它把以人为驱动的测试转变为以机器驱动，代替了我们手工执行测试的行为。 通过采用自动化测试，可以替代大量重复性的工作，提高测试效率 保证每次测试的一致性和可重复性。由于每次自动化测试执行时脚本都是相同的，所以每次执行的测试具有一致性，同时也可以提高回归测试的效率。 可以更好的利用非工作时间。由于自动化测试能够哪找计划自动执行，因此就可以利用非工作时间使用自动化测试来执行测试。测试用例编写规范| 用例编号 | 用例标题 | 测试模块/项目 | 用例级别 | 预置条件 | 测试步骤 | 测试数据 | 预期结果 || — | — | — | — | — | — | — | — || | 预期结果(测试点) | | | | | | || login_001 | 登陆失败（手机号未注册+非空密码） | login | P1 | 1.APP应用正常2.网络正常 | 1.打开登录页面2.输入手机号3.输入密码4.点击登录 | 手机号：13257894512密码：1458796 | 登陆失败。提示：“手机号未注册”| Selenium Selenium组件 介绍 Selenium WebDriver 模拟用户操作浏览器 Selenium IDE 提供录制Selenium测试用例 Selenium Grid 模拟多个操作系统/浏览器执行测试用例 LinuxLinux如何实时查看日志记录？ 命令 描述 less filename tail notes.log 默认显示最后 10 行。 -f 循环读取-c&lt;数目&gt; 显示的字节数-n&lt;行数&gt; 显示文件的尾部 n 行内容 || tail -f filename | 把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，只要 filename 更新就可以看到最新的文件内容。 || tail -n +20 notes.log | 显示文件 notes.log 的内容，从第 20 行至文件末尾 || tail -c 10 notes.log | 显示文件 notes.log 的最后 10 个字符: | linux命令，统计一个文本中关键字出现的次数grep -o targetStr filename | wc -l linux 查找当前目录下所有后缀为 .py文件find ./ -name &quot;*.py&quot; linux常用命令：查看指定端口进程# 查看某进程端口占用情况 ps -ef |grep tomcat ps -p PID 查看进程的详细信息 场景题设计购物车测试用例搜索页面设计测试用例抢红包设计测试用例微信朋友圈测试用例支付测试用例淘宝搜索框测试用例开放性问题怎么理解的测开这个岗位","categories":[{"name":"测试","slug":"测试","permalink":"https://xingxin-99.github.io/categories/测试/"}],"tags":[{"name":"测试","slug":"测试","permalink":"https://xingxin-99.github.io/tags/测试/"}],"keywords":[{"name":"测试","slug":"测试","permalink":"https://xingxin-99.github.io/categories/测试/"}]},{"title":"WebSocket","slug":"WebSocket","date":"2023-08-26T10:50:39.000Z","updated":"2023-08-27T08:19:55.542Z","comments":true,"path":"2023/08/26/WebSocket/","link":"","permalink":"https://xingxin-99.github.io/2023/08/26/WebSocket/","excerpt":"","text":"WebSocketWbeSocket是一个基于TCP的一种新的网络协议（ws协议）（不同于Http协议），是一种全双工的通信协议，它即允许浏览器向服务器端推送消息，同时也允许服务器端向浏览器推送消息。浏览器和服务器只需要经历一次握手，就可以创建一个持久性连接，并在连接中进行双向数据传输。 WebSocket和Http有什么不同？WebSocket是一种全双工的通信方式，它允许两端都可以主动的向对方推送消息，因此Websocket更像是现实生活中打电话的场景，电话接通后，双方都可以听到对方的信息。而Http它是请求响应模式，由客户端发出请求，浏览器回以响应。 Websocket的应用场景（页面不刷新，但数据可以实时变化）视频弹幕、网页聊天（通过Websocket把聊天消息推送到页面中显示）、体育实况更新、股票基金报价实时更新 WebSocket的原理是什么？客户端向服务器发送建立连接的请求，此时发送的请求信息如下： GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 Origin: http://example.com Upgrade: 在 HTTP 请求中，Upgrade 头部字段通知服务器客户端希望升级到其他协议。它指示服务器在响应中是否支持升级，并将协议更改为请求中指定的协议。Connection: Upgrade : 在 HTTP 请求中，Connection 头部字段指示客户端是否希望与服务器建立持久连接。而当与 Upgrade 头部一同使用时，Connection: Upgrade 表示客户端希望升级到其他协议，并要求服务器在响应中进行协议升级。在服务器的响应中，如果支持升级到 WebSocket，会包含如下的响应头部： HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= 这样，客户端和服务器之间的连接就会从普通的 HTTP 连接升级为 WebSocket 连接，后续通信将使用 WebSocket 协议。 在WeSocket之前是如何进行实时通信的？ 轮询。客户端定期向服务器发送请求，判断服务器中是否有新的数据可用。拿来单提醒这个功能举例，如果不使用WebSocket，就需要客户端向服务端轮询的发起查询请求，判断数据库中是否存在新的还未进行来单提醒订单数据，如果存在的话，则将来单提醒需要的信息返回给前端。缺点：会在客户端与服务器之间产生大量的请求与响应，导致不必要的网络开销和延迟。 长轮询。客户端发出请求后，保持连接打开，等待新数据响应后在关闭连接。优缺点：解决了无效轮询的数量，但仍然需要频繁建立和关闭连接。 Comet。模拟实时通信，在返回请求后继续保持连接打开。核心思想是保持长连接来实现实时通信，并允许服务器通过流式传输等推送技术来主动向客户端推送消息。缺点： 该方法依然依赖于无状态的HTTP连接，其要求服务器端有特殊的功能(类似于流式传输等推送技术)来临时挂起连接。 WebSocket的优势 双向实时通信。在单个、长时间的连接上进行双向实时通信。在需要快速实时更新的应用程序里，比HTTP更高效。 降低延迟。数据可用在客户端与服务器之间以比HTTP更低的延迟进行传输。（头部相对较小；在长连接里传输数据，不必在每次建立连接） 更高效的资源利用。由于连接只建立了一次，因此减少了重复请求和响应的开销 WebSocket的限制 不提供加密功能。如果传输的数据要保证安全性，需采用像SSL这样的协议 不支持古老浏览器。 保持长连接需要服务器不断维护和处理连接的状态。 实现步骤 使用websocket.html页面作为WebSocket客户端（由客户端向服务端发送握手请求，服务端响应后，二者就建立了持久连接） 导入WebSocket的maven坐标 导入WebSocket服务端组件WebSocketServer（接收客户端发来的请求并处理，类似于Controller），用于和客户端通信 导入配置类WebSocketConfiguration，注册WebSocket的服务端组件 导入定时任务类WebSocketTask，定时向客户端推送数据（用于测试，可有可无） 函数/注解 作用 new WebSocket(url) 向地址为url的服务端建立连接，并返回ws对象，里面提供了连接相关的API @ServerEndpoint(“/ws/{sid}”) 将目前的类定义成一个websocket服务器端, 注解的值将被用于监听用户连接的终端访问URL地址,客户端可以通过这个URL来连接到WebSocket服务器端 @OnOpen 连接建立成功调用方法 @OnMessage 收到客户端消息后调用方法 WebSocket组件package com.sky.websocket; import org.springframework.stereotype.Component; import javax.websocket.OnClose; import javax.websocket.OnMessage; import javax.websocket.OnOpen; import javax.websocket.Session; import javax.websocket.server.PathParam; import javax.websocket.server.ServerEndpoint; import java.util.Collection; import java.util.HashMap; import java.util.Map; /** * WebSocket服务 */ @Component //标识该类为WebSokcet服务器端，监听该URL地址，客户端可通过该URL连接到该服务器端 @ServerEndpoint(&quot;/ws/{sid}&quot;) public class WebSocketServer { //存放会话对象 //一个Session就是一个会话，当客户端与服务端建立连接后，就会生成一个session会话 private static Map&lt;String, Session&gt; sessionMap = new HashMap(); /** * 连接建立成功调用的方法 * sid为客户端的标识，连接建立成功则把该会话存入到map中 */ @OnOpen public void onOpen(Session session, @PathParam(&quot;sid&quot;) String sid) { System.out.println(&quot;客户端：&quot; + sid + &quot;建立连接&quot;); sessionMap.put(sid, session); } /** * 收到客户端消息后调用的方法 * * @param message 客户端发送过来的消息 */ @OnMessage public void onMessage(String message, @PathParam(&quot;sid&quot;) String sid) { System.out.println(&quot;收到来自客户端：&quot; + sid + &quot;的信息:&quot; + message); } /** * 连接关闭调用的方法 * * @param sid */ @OnClose public void onClose(@PathParam(&quot;sid&quot;) String sid) { System.out.println(&quot;连接断开:&quot; + sid); sessionMap.remove(sid); } /** * 群发 * * @param message */ public void sendToAllClient(String message) { Collection&lt;Session&gt; sessions = sessionMap.values(); for (Session session : sessions) { try { //服务器向客户端发送消息 session.getBasicRemote().sendText(message); } catch (Exception e) { e.printStackTrace(); } } } } 定义配置类，注册WebSocket的服务端组件 package com.sky.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.socket.server.standard.ServerEndpointExporter; /** * WebSocket配置类，用于注册WebSocket的Bean */ @Configuration public class WebSocketConfiguration { @Bean public ServerEndpointExporter serverEndpointExporter() { return new ServerEndpointExporter(); } } 来单提醒功能实现 通过WebSocket来实现管理端页面和服务端保持长连接服务端：引入WebSocket依赖，注册WebSokcet组件，监听Websocket客户端发送的建立连接消息浏览器：在前端页面中已经写好了WebSocket相关的js代码，登录成功后，页面解析js代码，向服务端发送建立连接的请求，服务端收到请求后响应消息，客户端和服务端的长连接建立成功，之后双方便可通过该连接推送消息 当客户支付后，调用WebSocket的相关API实现服务端向客户端推送消息当客户支付成功后，微信端会调用我们写好的一个回调方法paySuccess()来执行支付成功后的处理逻辑，因此我们在该回调函数的逻辑中补充了由服务器端向客户端推送消息的代码。主要逻辑：注入WebSocketServer对象，生成我们要发送到客户端的JSON消息，调用写好的向客户端推送消息的API（浏览器端与服务器端建立长连接后生成一个session对象，通过这个session对象向客户端发送消息），将该消息推送到客户端页面 @Autowired private WebSocketServer webSocketServer; /** * 支付成功，修改订单状态 * * @param outTradeNo */ public void paySuccess(String outTradeNo) { // 当前登录用户id Long userId = BaseContext.getCurrentId(); // 根据订单号查询当前用户的订单 Orders ordersDB = orderMapper.getByNumberAndUserId(outTradeNo, userId); // 根据订单id更新订单的状态、支付方式、支付状态、结账时间 Orders orders = Orders.builder() .id(ordersDB.getId()) .status(Orders.TO_BE_CONFIRMED) .payStatus(Orders.PAID) .checkoutTime(LocalDateTime.now()) .build(); orderMapper.update(orders); ////////////////////////////////////////////// Map map = new HashMap(); map.put(&quot;type&quot;, 1);//消息类型，1表示来单提醒 map.put(&quot;orderId&quot;, orders.getId()); map.put(&quot;content&quot;, &quot;订单号：&quot; + outTradeNo); //通过WebSocket实现来单提醒，向客户端浏览器推送消息 webSocketServer.sendToAllClient(JSON.toJSONString(map)); /////////////////////////////////////////////////// } /** * 群发 * * @param message */ public void sendToAllClient(String message) { Collection&lt;Session&gt; sessions = sessionMap.values(); for (Session session : sessions) { try { //服务器向客户端发送消息 session.getBasicRemote().sendText(message); } catch (Exception e) { e.printStackTrace(); } } } 客户端浏览器解析服务端推送的消息，判断是来单提醒还是客户催单，进行相应的消息提示和语音播报（前端页面已实现） 约定服务端发送给客户端浏览器的数据格式为JSON，字段包括：type，orderId，content type 为消息类型，1为来单提醒 2为客户催单 orderId 为订单id content 为消息内容 参考一文吃透 WebSocket 原理 刚面试完，趁热赶紧整理 - 掘金10 分钟 理论 + 实操 搞懂 WebSocket_哔哩哔哩_bilibili","categories":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}],"tags":[{"name":"WebSocket","slug":"WebSocket","permalink":"https://xingxin-99.github.io/tags/WebSocket/"}],"keywords":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}]},{"title":"JWT安全认证","slug":"JWT安全认证","date":"2023-08-26T10:50:12.000Z","updated":"2023-08-26T10:57:05.254Z","comments":true,"path":"2023/08/26/JWT安全认证/","link":"","permalink":"https://xingxin-99.github.io/2023/08/26/JWT安全认证/","excerpt":"","text":"JWT安全认证JWT的全称为Json Web Tocken，它通过数字签名的方式，以Json对象为载体，实现在客户端和服务器之间安全的传输数据。JWT由三部分组成，这三部分分别是Header、Payload、Signature，这三部分之间用.拼接。当用户第一次登录后，生成JWT，并将其以tocken返回给前端。后续客户端每次发起的请求都包含JWT。系统在处理请求之前，会先使用拦截器拦截请求，对请求中的JWT进行安全校验，通过之后才放行 JWT组成 Header由两部分组成：token的类型以及签名算法的名称。 { &#39;alg&#39;: &quot;HS256&quot;, &#39;typ&#39;: &quot;JWT&quot; } 用Base64对这个JSON编码就得到JWT的第一部分 Payload(负载)：在负载中可以声明一些用于传输的数据，比如用户名等信息 { &quot;sub&quot;: &#39;1234567890&#39;, &quot;name&quot;: &#39;john&#39;, &quot;admin&quot;:true } Signature：对head和payload按照指定的签名算法进行签名，保证JWT没有被篡改过 var encodedString = base64UrlEncode(header) +&#39;.&#39;+ base64UrlEncode(payLoad); var signature = HMACSHA256(encodedString,&#39;secret&#39;); 如何能确保JWT没有被篡改过？ 首先，JWT由头部、负载、签名三部分组成，头部包含了tocken类型以及使用的签名算法，而负载中有我们所声明的JSON型的数据信息，而签名是对头部和负载进行base64编码后，通过签名算法以及服务器端生成的秘钥对base64编码后的头部和负载进行签名。如果有人对头部和负载内容解码之后再生成新的JWT，由于它不知道服务器端秘钥，因此服务器端进行JWT校验失败，就判断此JWT已经被篡改。 参考：JWT详细教程与使用jwt教程一支有理想的月月鸟的博客-CSDN博客 在项目中如何实现JWT安全认证的？ 引入JWT的相关依赖 通过Jwts.builder去创建一个jwt，通过setClaims方法设置私有声明，私有声明就是我们想在服务器与客户端传送的数据，通过signWith方法设置签名使用的签名算法及签名秘钥，通过setExpiration方法设置签名过期时间，通过compact方法将这些信息组合，生成JWT public class JwtUtil { /** * 生成jwt * 使用Hs256算法, 私匙使用固定秘钥 * * @param secretKey jwt秘钥 * @param ttlMillis jwt过期时间(毫秒) * @param claims 设置的信息 * @return */ public static String createJWT(String secretKey, long ttlMillis, Map&lt;String, Object&gt; claims) { // 指定签名的时候使用的签名算法，也就是header那部分 SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; // 生成JWT的时间 long expMillis = System.currentTimeMillis() + ttlMillis; Date exp = new Date(expMillis); // 设置jwt的body JwtBuilder builder = Jwts.builder() // 如果有私有声明，一定要先设置这个自己创建的私有的声明，这个是给builder的claim赋值，一旦写在标准的声明赋值之后，就是覆盖了那些标准的声明的 .setClaims(claims) // 设置签名使用的签名算法和签名使用的秘钥 .signWith(signatureAlgorithm, secretKey.getBytes(StandardCharsets.UTF_8)) // 设置过期时间 .setExpiration(exp); return builder.compact(); } /** * Token解密 * * @param secretKey jwt秘钥 此秘钥一定要保留好在服务端, 不能暴露出去, 否则sign就可以被伪造, 如果对接多个客户端建议改造成多个 * @param token 加密后的token * @return */ public static Claims parseJWT(String secretKey, String token) { // 得到DefaultJwtParser Claims claims = Jwts.parser() // 设置签名的秘钥 .setSigningKey(secretKey.getBytes(StandardCharsets.UTF_8)) // 设置需要解析的jwt .parseClaimsJws(token).getBody(); return claims; } } 后端将tocken传递到前端，那么之后每次发送请求时，请求的header中都携带该tocken信息。当前端发起请求时，首先会在拦截器中拦截该请求，并从请求头中获取该tocken进行JWT校验，校验失败则返回“用户未登录”的信息。校验成功则放行，继续接下来的处理逻辑。 /** * jwt令牌校验的拦截器 */ @Component @Slf4j public class JwtTokenAdminInterceptor implements HandlerInterceptor { @Autowired private JwtProperties jwtProperties; /** * 校验jwt * * @param request * @param response * @param handler * @return * @throws Exception */ public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //判断当前拦截到的是Controller的方法还是其他资源 if (!(handler instanceof HandlerMethod)) { //当前拦截到的不是动态方法，直接放行 return true; } //1、从请求头中获取令牌 String token = request.getHeader(jwtProperties.getAdminTokenName()); //2、校验令牌 try { log.info(&quot;jwt校验:{}&quot;, token); Claims claims = JwtUtil.parseJWT(jwtProperties.getAdminSecretKey(), token); Long empId = Long.valueOf(claims.get(JwtClaimsConstant.EMP_ID).toString()); /////将用户id存储到ThreadLocal//////// BaseContext.setCurrentId(empId); //////////////////////////////////// log.info(&quot;当前员工id：&quot;, empId); //3、通过，放行 return true; } catch (Exception ex) { //4、不通过，响应401状态码 response.setStatus(401); return false; } } } sky: jwt: # 设置jwt签名加密时使用的秘钥 admin-secret-key: itcast # 设置jwt过期时间 admin-ttl: 7200000 # 设置前端传递过来的令牌名称 admin-token-name: token user-secret-key: itheima user-ttl: 7200000 user-token-name: authentication @Component @ConfigurationProperties(prefix = &quot;sky.jwt&quot;) @Data public class JwtProperties { /** * 管理端员工生成jwt令牌相关配置 */ private String adminSecretKey; private long adminTtl; private String adminTokenName; /** * 用户端微信用户生成jwt令牌相关配置 */ private String userSecretKey; private long userTtl; private String userTokenName; } cookie、session、token的区别由于Http是无状态协议，因此对于服务器来说，它接收到的每个请求都是独立的请求，服务器并不会去记录每个请求之间的联系。但是对于更多的使用场景，我们需要去让服务器记录此次发来的请求是哪个客户端发送来的，比如用户登录进某个网站之后，那么接下来的请求，用户就不需要每次在重复登录，进行身份验证。而通过cookie、session、token我们就能够让服务器端识别发起请求的客户端。 cookie它是存储在浏览器中的，并且cookie的大小有限制，一般不超过4KB。由于cookie存储在客户端的，因此一般认为cookie不够安全，别人可以直接对本地的cookie进行分析。当浏览器向服务器端发送请求时，那么服务器端首先会判断是否已经为发出该请求的客户端创建了对应的session，如果没有的话，则创建session，并在响应头中设置set-cookie，set-cookie中包含了生成的sessionId。浏览器接收到该响应后，浏览器在下次请求头中自动携带cookie。服务器端接收到请求之后先验证cookie信息，比如验证cookie中的session信息是否存在，存在则正常响应，不存在则拦截返回错误信息。 session它是存储在服务器端的一个对象，它的大小没有限制，由于是存储在服务器端，因此一般认为session中存储的数据是安全的。当客户端与服务器端建立连接后，它会在服务器端生成一个具有唯一sessionId的session。我们可以把用户的id信息存储到session中，当下次客户端发送请求时，通过判断该session中是否存在用户信息来判断用户的登录状态。但是session也有一些缺点，由于session它是保存在内存中的，因此当有很多客户端和服务器端建立连接时，那么就会在服务器端创建很多session，这样就占用了服务器的内存资源。另外session它并不适用于分布式的环境，比如当有两个tomcat服务器时，采用轮询方式访问服务器，那么用户就要进行多次登录。 tocken本质上我们可以把它看做一个加密后的字符串，它是由服务器生成，然后相应给客户端，客户端接收之后把它存储到localstorage等地方，之后客户端每次发送请求都会在请求头中携带tocken信息。tokcen","categories":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://xingxin-99.github.io/tags/JWT/"}],"keywords":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}]},{"title":"测试","slug":"测试","date":"2023-08-25T05:52:19.000Z","updated":"2023-08-25T07:15:16.994Z","comments":true,"path":"2023/08/25/测试/","link":"","permalink":"https://xingxin-99.github.io/2023/08/25/测试/","excerpt":"","text":"","categories":[{"name":"测试","slug":"测试","permalink":"https://xingxin-99.github.io/categories/测试/"}],"tags":[{"name":"测试","slug":"测试","permalink":"https://xingxin-99.github.io/tags/测试/"}],"keywords":[{"name":"测试","slug":"测试","permalink":"https://xingxin-99.github.io/categories/测试/"}]},{"title":"项目","slug":"项目","date":"2023-08-25T05:51:45.000Z","updated":"2023-08-25T07:15:12.645Z","comments":true,"path":"2023/08/25/项目/","link":"","permalink":"https://xingxin-99.github.io/2023/08/25/项目/","excerpt":"","text":"","categories":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}],"tags":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/tags/项目/"}],"keywords":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}]},{"title":"MySQL","slug":"MySQL","date":"2023-08-25T05:50:48.000Z","updated":"2023-08-25T07:15:46.000Z","comments":true,"path":"2023/08/25/MySQL/","link":"","permalink":"https://xingxin-99.github.io/2023/08/25/MySQL/","excerpt":"","text":"","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://xingxin-99.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://xingxin-99.github.io/tags/MySQL/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"https://xingxin-99.github.io/categories/MySQL/"}]},{"title":"Redis","slug":"Redis","date":"2023-08-25T05:50:30.000Z","updated":"2023-08-25T07:22:28.702Z","comments":true,"path":"2023/08/25/Redis/","link":"","permalink":"https://xingxin-99.github.io/2023/08/25/Redis/","excerpt":"","text":"","categories":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}]},{"title":"Spring","slug":"Spring","date":"2023-08-25T05:49:03.000Z","updated":"2023-08-25T07:15:18.553Z","comments":true,"path":"2023/08/25/Spring/","link":"","permalink":"https://xingxin-99.github.io/2023/08/25/Spring/","excerpt":"","text":"","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xingxin-99.github.io/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://xingxin-99.github.io/tags/Spring/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://xingxin-99.github.io/categories/Spring/"}]},{"title":"点评项目","slug":"点评项目","date":"2023-06-26T09:01:04.000Z","updated":"2023-08-26T10:55:40.952Z","comments":true,"path":"2023/06/26/点评项目/","link":"","permalink":"https://xingxin-99.github.io/2023/06/26/点评项目/","excerpt":"","text":"一、短信登陆集群Session问题每个Tomcat服务器都有自己独立的Session空间，多个Tomcat服务器不会共享Session存储空间，因此当请求切换到其他的Tomcat服务器时，由于该服务器的Session中并没有保存用户相关信息，因此请求会被拦截，需要用户重新进行登录校验，导致用户体验感变差。解决方案： Session拷贝 在不同的session中存储相同数据，浪费空间 维护数据同步浪费资源 数据不一致 替代Session session中存储的是登录校验的数据，在每次请求中都会被访问。而session是基于内存的，读写效率高。因此要求替代品要求有较高的读写效率（基于内存） 能实现数据共享（Redis独立于Tomcat之外，任何一个tomcat都能访问到redis） key、value结构 Redis保存数据将验证码和用户信息保存到redis中。保存用户信息到redis中时，考虑到后续每次请求都会通过key，找到value；通过判断value是否存来进行登录校验。因此需要设计合适的key。 key value phone:13507690339 9874 tocken: {name:;} 特殊情况：在拦截器中只拦截了必须登录才有权限看到的页面，对于首页等这种无需登录的页面并没有拦截。如果用户一直在这种页面中，那么tokcen的有效期就不会刷新，因此tocken到时间之后会失效。需求：只要用户在浏览页面，就让tocken刷新。因此设置两个拦截器，第一个拦截器拦截所有页面，用于刷新tocken；第二个拦截器进行身份校验。优化：使用JWT来进行登录校验。这样就不需要再将用户的信息保存到redis中，而是可以在tocken中获取用户信息。 二、缓存缓存：数据交换的缓冲区，临时存储数据的地方，读写性能比较高实际开发中,会构筑多级缓存来使系统运行速度进一步提升,例如:本地缓存与redis中的缓存并发使用浏览器缓存：主要是存在于浏览器端的缓存应用层缓存：可以分为tomcat本地缓存，比如之前提到的map，或者是使用redis作为缓存数据库缓存：在数据库中有一片空间是 buffer pool，增改查数据都会先加载到mysql的缓存中CPU缓存：当代计算机最大的问题是 cpu性能提升了，但内存读写速度没有跟上，所以为了适应当下的情况，增加了cpu的L1，L2，L3级的缓存 缓存更新 已经存储到redis中的数据，什么时候会触发更新操作？ 内存淘汰 当Redis的内存满了之后，触发内存淘汰机制，自动淘汰掉Redis中的一部分数据 超时剔除 当向Redis中存储数据时，设置数据的过期时间，到期自动删除。下次查询时发现缓存不存在，从数据库中查询，再写入到缓存中。不足：若数据在有效期内进行了修改，从Redis中获取的仍然是旧数据 主动更新 由程序员编写业务逻辑，当修改数据库时，同时更新缓存中的数据。 主动更新策略 Cache Aside Pattern 缓存穿透 项目中对商铺信息进行了缓存，如果在某一时刻有大量请求去查询了不存在的商铺，造成缓存穿透现象，该怎么解决？ 缓存空对象先查询缓存，判断商铺信息是否存在。如果存在，还需判断商铺对应的Key缓存的Value是否是空对象(“”)。如果是的话，则返回店铺不存在的错误信息。如果不是空对象的话，则说明数据库中有该商铺信息的数据。则到数据库中进行查询，并存入到redis中。 布隆过滤器增加ID复杂度，避免被猜测ID规律防止被猜到不存在数据库中的ID，而被恶意的向这些ID发起大量查询请求 对ID进行格式校验先对ID进行校验，把不符合格式的ID的请求过滤掉 对热点参数做限流缓存雪崩解决方案 为不同的Key的TTL添加随机值（如果是做了缓存预热，批量将一批key添加至缓存，并设置TTL，那么为了不让这批key同一时间过期而导致缓存血崩的问题，将key设置30min+产生的一个随机数，让TTL随机） 利用Redis集群提高服务的可用性（解决宕机导致Redis雪崩的思路） 给缓存业务添加降级限流的策略（比如当Redis的整个集群都宕机时，添加快速失败、拒绝服务等策略） 给业务添加多级缓存（多个层面建立缓存，一个缓存崩掉了，还有其他的缓存起一个缓冲作用，浏览器本地-&gt;Nginx-&gt;Redis-&gt;JVM-&gt;数据库，像京东为商品详情就做了多级缓存，从而应对亿级以上的并发） 缓存击穿缓存击穿问题也叫热点Key问题，就是一个被高并发访问（比如秒杀商品）并且缓存重建业务较复杂（比如这个数据需要多表关联运算，查取比较耗时）的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。解决方案： 互斥锁（一致性）优点：没有额外的内存消耗（没有添加expire字段） 保证了强一致性 实现简单缺点：性能较低（其中一个线程进行缓存重建时，其他想要读取该数据的线程都会处于等待状态） 有死锁风险 逻辑过期（可用性）（一般是为热点Key设置逻辑过期，比如某一秒杀商品详情信息，当秒杀商品下架时，再把该key从Redis中移除。）优点：性能较好，线程无须等待缺点：不保证一致性 有额外内存消耗（添加了expire字段） 实现复杂在向Redis中添加数据时，设置一个逻辑过期字段expire，值为存入的系统当前时间+有效期流程：线程1查询Redis，发现数据过期，则获取互斥锁，同时开启另一个线程去读取数据库的数据，重建缓存。线程1仍然读取旧数据，并缓存。此时其他线程从Redis中查询数据，发现逻辑过期，尝试获取互斥锁来重建缓存。但获取互斥锁失败，则返回过期数据。 互斥锁实现由于Redis中设置Key时，有一个命令SETNX，它只有key不存在时，才会设置值，同时返回结果1。如果key不存在，则返回0。因此可以通过它来实现互斥锁，如果有一个线程想要获取互斥锁，则根据SETNX来为某一个key设置值，同时返回true，那么该线程则知道获取锁成功。其他的线程想要获取该互斥锁时，发现SETNX返回的结果为0，则知道已经有线程获取了该锁。当持有互斥锁的线程进行缓存重建后，要释放互斥锁，否则其他线程将会一直处于重试等待状态。另外，考虑到如果释放互斥锁执行失败，导致锁没有释放掉，其他线程一直等待，因此可以在SETNX时，为互斥锁的key添加过期时间。比如缓存重建业务的时间可能为100ms，则设置互斥锁的过期时间为它的10倍左右，设置为1000ms。 // 获取锁 private boolean tryLock(String key) { Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, 10, TimeUnit.SECONDS); return BooleanUtil.isTrue(flag); } // 释放锁 private void unlock(String key) { stringRedisTemplate.delete(key); } public Shop queryShopByIdSolvePenetrateWithWriteMutex(Long id) { String shopJson = stringRedisTemplate.opsForValue().get(CACHE_SHOP_KEY + id); //如果redis未命中查数据库 if (StrUtil.isNullOrUndefined(shopJson)){ //在查数据库之前先获取锁 String lockKey=LOCK_SHOP_KEY+id; try { boolean isLock = tryLock(lockKey); if (!isLock){ //如果获取锁失败了休眠一段时间后重试 Thread.sleep(50); return queryShopByIdSolvePenetrateWithWriteMutex(id); } //以下为获得锁成功 Shop shop = shopService.getById(id); //数据库也不存则写入空数据到Redis if (shop==null){ // stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id,&quot;&quot;,CACHE_NULL_TTL,TimeUnit.MINUTES); queryShopByIdSolveBreakWithWriteNull(id); } //数据库存在则将数据写进redis shopJson = JSONUtil.toJsonStr(shop); stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY+id,shopJson,CACHE_SHOP_TTL,TimeUnit.MINUTES); //写进缓存后再释放锁 } catch (InterruptedException e) { e.printStackTrace(); } finally { unlock(lockKey); } //重新查一遍，就可以从redis获得数据 return queryShopByIdSolveBreakWithWriteNull(id); } //如果命中了redis,但是为空,直接返回空对象 if (StrUtil.isBlank(shopJson)){ return null; } //如果命中了redis且不为空,重置时间 stringRedisTemplate.expire(CACHE_SHOP_KEY+id,CACHE_SHOP_TTL,TimeUnit.MINUTES); Shop shop = JSONUtil.toBean(shopJson, Shop.class); return shop; } 逻辑过期实现 逻辑过期字段怎么添加？ 直接在实体类中添加逻辑过期字段（违背开闭原则） 设计一个新的类，类里有逻辑过期字段，让实体类继承该类（仍然违背开闭原则） 设计一个新的类，类里有逻辑过期以及实体类两个属性（采用） @Data public class RedisData { private LocalDateTime expireTime; private Object data; } 逻辑过期代码如何实现？ 由于需要开启一个独立线程去执行缓存重建，因此创建了一个线程池（线程的创建和销魂不用我们关心），并在线程池里去提交缓冲重建的任务。 //创建一个固定线程池 private static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10); /** * 用逻辑过期时间解决缓存穿透 * @param id * @return */ public Shop queryShopByIdSolvePenetrateWithWriteLogicalExpireTime(Long id) { String redisDataJson = stringRedisTemplate.opsForValue().get(CACHE_SHOP_KEY + id); //如果redis未命中查数据库 if (StrUtil.isEmpty(redisDataJson)){ //未命中说明不是热点数据（会把热点数据进行缓存预热，存入到Redis中），转入处理缓存击穿的函数 return null; } //如果命中了redis且不为空，将其反序列化成对象，拿到逻辑过期时间 RedisData redisData = JSONUtil.toBean(redisDataJson, RedisData.class); Shop shop = JSONUtil.toBean((JSONObject) redisData.getData(), Shop.class); LocalDateTime expireTime = redisData.getExpireTime(); //如果时间已经过期，直接返回旧数据并开启新线程修改数据 if (expireTime.isBefore(LocalDateTime.now())){ //在开启新线程之前获得锁，锁的名称要与锁的id关联，修改不同的id可以并行，一样的id才需要加锁 String lockKey=LOCK_SHOP_KEY+id; try { boolean isLock = tryLock(lockKey); //获取锁成功 if (isLock){ //开启新线程用线程池，性能比自己创建线程好 CACHE_REBUILD_EXECUTOR.execute(()-&gt;{ //重建缓存 saveShopWithExpireTimeToRedis(id,30L); }); } } catch (Exception e) { e.printStackTrace(); } finally { unlock(lockKey); } } return shop; } 三、秒杀问题优惠券字段结构 全局唯一ID 如果订单ID为自增型，会存在什么样的问题？（订单特点：数据量大、唯一） ID规律太明显。由于订单ID会暴露给用户，因此用户可以从ID推测出一些信息。（比如，今天某一用户下订单时，订单ID为100；到第二天，下订单时订单ID为200，因此如果是自增的话，用户就能推测到在此期间卖掉了100单。） 受单表数据量的限制（如果采取自增，则之后对表做拆分，会出现订单重复） 全局唯一ID生成策略有哪些 UUID（十六进制字符串，无单调递增的特性） Redis自增 snowflake算法（采用long类型64位数字，和下面采用的Redis生成ID策略很相似）自增采用的当前机器的自增，而Redis是不管用的任何分布式系统，都是用的Redis作为自增。 数据库自增 全局ID生成器（把Redis作为全局ID生成器）由于Redis是全局的，独立于Mysql之外的，因此可以使用Redis中的自增数值来实现生成全局唯一ID特点： 唯一性 高可用（找该生成器生成ID时，这个生成器不能宕机） 高性能（生成ID速度快） 递增性（递增的话，方便建立和维护索引） 安全性（不能被用户猜测到ID规律） ID采用数值类型（long型8个字节），数值类型在数据库中占用空间更小且建立索引更方便如果时间戳相同，可以通过序列号来生成不同ID 代码实现 生成的序列号为什么还要拼接上时间？ Reids的自增数值上限2^64，如果对于一个业务，全都按照相同的key递增，那么经过几年之后可能就会出现数值超出的异常。解决（一天一个key）：以天为单位，拼上时间，每一天都有不同的key，让其重新递增。另外这种方式还可以起到一个统计的效果。 long count = stringRedisTemplate.opsForValue().increment(&quot;icr:&quot; + keyPrefix); //并没有采取这种方案 // 2.生成序列号 // 2.1.获取当前日期，精确到天 String date = now.format(DateTimeFormatter.ofPattern(&quot;yyyy:MM:dd&quot;)); // 2.2.自增长 long count = stringRedisTemplate.opsForValue().increment(&quot;icr:&quot; + keyPrefix + &quot;:&quot; + date); 如何将时间戳和序列号进行拼接？ 由于返回的为long型，因此不能利用String进行简单的拼接。让时间戳在高位而序列号在低位的话，可以通过位运算让时间戳移动到高位，再通过或运算让序列号填充在低位。 timestamp &lt;&lt; COUNT_BITS | count 整体代码实现： public class RedisIdWorker { /** * 开始时间戳：以2020年0点0分为起点 */ private static final long BEGIN_TIMESTAMP = 1640995200L; /** * 序列号的位数 */ private static final int COUNT_BITS = 32; private StringRedisTemplate stringRedisTemplate; public RedisIdWorker(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } // keyPrefix:可以看做是业务前缀，比如订单业务，店铺业务等 public long nextId(String keyPrefix) { // 1.生成时间戳 LocalDateTime now = LocalDateTime.now(); long nowSecond = now.toEpochSecond(ZoneOffset.UTC); long timestamp = nowSecond - BEGIN_TIMESTAMP; // 2.生成序列号 // 2.1.获取当前日期，精确到天 String date = now.format(DateTimeFormatter.ofPattern(&quot;yyyy:MM:dd&quot;)); // 2.2.自增长 long count = stringRedisTemplate.opsForValue().increment(&quot;icr:&quot; + keyPrefix + &quot;:&quot; + date); // 3.拼接并返回 return timestamp &lt;&lt; COUNT_BITS | count; } } 实现优惠秒杀下单平价劵特价劵（劵信息的补充）订单接口下单时需要判断两点： 秒杀是否开始或结束，如果尚未开始或已经结束则无法下单 库存是否充足，不足则无法下单 超卖问题 如果使用乐观锁，每次只能以数据是否变更为依据，那该怎么优化？ 分段锁。将库存分到多张表里，每次锁一个表中的数据（类似jdk1.7中的ConcurrentHashMap分段锁的思想） 乐观锁版本号法CAS法（通过库存数据本身有没有变化来判断能不能进行减库存操作） //获取库存 int stock = seckillVoucherService.getStockById(Id); // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(&quot;stock = stock - 1&quot;) // set stock = stock - 1 .eq(&quot;voucher_id&quot;, voucherId).eq(&quot;stock&quot;, stock) // where id = ? and stock &gt; 0 .update(); 并发测试（在进行CAS优化超卖问题后，进行并发测试，异常比例大大增加）模拟200个并发请求异常值高达90%在最开始的请求中就出现库存不足的错误信息库存卖出21件生成21条订单数据（没有出现超卖问题）分析问题原因（认为只要有线程更改，就会产生并发安全问题）：在库存数量充足的情况下，同一时间仍然只能有一个线程能对库存更新成功，其他线程由于查询库存数量变化，均导致更新失败，成功率过低。优化： // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(&quot;stock = stock - 1&quot;) // set stock = stock - 1 .eq(&quot;voucher_id&quot;, voucherId).gt(&quot;stock&quot;, 0) // where id = ? and stock &gt; 0 .update(); 并发测试200个并发请求，100个线程下单成功，异常50%，符合预期数据库中优惠券库存为0数据库中订单数量为100 一人一单 实现思路是什么？ 当用户下单时，先根据用户id和优惠券id查询订单表中是否已经存在了该订单，如果存在，则返回异常结果。如果不存在，则走下单逻辑。解决思路：根据查询出来的订单数量，判断是否重复下单 // 5.1.查询订单 int count = query().eq(&quot;user_id&quot;, userId).eq(&quot;voucher_id&quot;, voucherId).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 log.error(&quot;不允许重复下单！&quot;); return; } 并发测试（模拟一个用户发起的200个请求）由于发送的请求头中携带的是相同的tocken，因此服务器识别为同一个用户失败比例95%库存数量：-10（100 -&gt; 90）订单数量：10 （0 -&gt; 10） 为什么实现了一人一单的逻辑后，仍然出现了一个用户下多个订单的问题？ 这仍然是因为多线程并发时，多个线程同时查询得到了count为0，然后进行了扣减库存的操作。和库存超卖问题类似。解决思路：将查询订单数量和生成订单变成原子性操作Sycronized锁解决 @Transactional public Result createVoucherOrder(Long voucherId) { // 5.一人一单 Long userId = UserHolder.getUser().getId(); //如果直接锁userId，每次锁住的其实是不同的userId对象，因此没有作用 synchronized (userId.toString().intern()) { // 5.1.查询订单 int count = query().eq(&quot;user_id&quot;, userId).eq(&quot;voucher_id&quot;, voucherId).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 return Result.fail(&quot;用户已经购买过一次！&quot;); } // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(&quot;stock = stock - 1&quot;) // set stock = stock - 1 .eq(&quot;voucher_id&quot;, voucherId).gt(&quot;stock&quot;, 0) // where id = ? and stock &gt; 0 .update(); if (!success) { // 扣减失败 return Result.fail(&quot;库存不足！&quot;); } // 7.创建订单 VoucherOrder voucherOrder = new VoucherOrder(); // 7.1.订单id long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); // 7.2.用户id voucherOrder.setUserId(userId); // 7.3.代金券id voucherOrder.setVoucherId(voucherId); save(voucherOrder); // 7.返回订单id return Result.ok(orderId); } } 如果仅仅采用上述这种方式，那么在事务提交前，锁已经释放，此时创建订单的记录还未写入到数据库中。因此可能有其他线程获取锁，并创建订单，仍然造成多线程并发不安全的情况。解决思路：先获取锁-&gt;执行逻辑，提交事务-&gt;再释放锁。 public Result seckillVoucher(Long voucherId) { // 1.查询优惠券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); // 2.判断秒杀是否开始 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { // 尚未开始 return Result.fail(&quot;秒杀尚未开始！&quot;); } // 3.判断秒杀是否已经结束 if (voucher.getEndTime().isBefore(LocalDateTime.now())) { // 尚未开始 return Result.fail(&quot;秒杀已经结束！&quot;); } // 4.判断库存是否充足 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(&quot;库存不足！&quot;); } // 5.一人一单 Long userId = UserHolder.getUser().getId(); synchronized (userId.toString().intern()) { Object proxy = AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } } @Transactional public Result createVoucherOrder(Long voucherId) { // 5.一人一单 Long userId = UserHolder.getUser().getId(); //如果直接锁userId，每次锁住的其实是不同的userId对象，因此没有作用 // 5.1.查询订单 int count = query().eq(&quot;user_id&quot;, userId).eq(&quot;voucher_id&quot;, voucherId).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 return Result.fail(&quot;用户已经购买过一次！&quot;); } // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(&quot;stock = stock - 1&quot;) // set stock = stock - 1 .eq(&quot;voucher_id&quot;, voucherId).gt(&quot;stock&quot;, 0) // where id = ? and stock &gt; 0 .update(); if (!success) { // 扣减失败 return Result.fail(&quot;库存不足！&quot;); } // 7.创建订单 VoucherOrder voucherOrder = new VoucherOrder(); // 7.1.订单id long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); // 7.2.用户id voucherOrder.setUserId(userId); // 7.3.代金券id voucherOrder.setVoucherId(voucherId); save(voucherOrder); // 7.返回订单id return Result.ok(orderId); } 为什么没有直接调用createVoucherOrder()，而是通过调用代理对象的createVoucherOrder()的方法？ Spring中的事务失效的一种情况。如果直接调用createVoucherOrder()，由于它并不是代理对象，因此不具有事务功能。并发测试200个请求中只有一个请求能下单成功，满足要求库存-1订单+1 上述这种方式会出现什么问题？ 在单体式情况下能保证一人一单的业务需求。但若将业务系统部署到多台服务器上，仍然会出现并发问题。虽然仍然是对同一个userId上锁，但由于不同的服务器都拥有自己的JVM，JVM常量池中的userId对象是不同的，因此它们关联的锁监视器也不同。当服务器1中的线程1获取了互斥锁后，有线程2想要获取服务器2的互斥锁，它发现锁监视器为空，因此仍然能获取互斥锁成功，导致仍然出现一人下多单的问题。解决思路：让所有的JVM共享一把锁（分布式锁） 四、分布式锁分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁。可见性：多个线程都能看到相同的结果，注意：这个地方说的可见性并不是并发编程中指的内存可见性，只是说多个进程之间都能感知到变化的意思互斥：互斥是分布式锁的最基本的条件，使得程序串行执行高可用（主要看是否支持集群模式）：程序不易崩溃，时时刻刻都保证较高的可用性高性能：由于加锁本身就让性能降低，所有对于分布式锁本身需要他就较高的加锁性能和释放锁性能安全性（比如锁的释放）：安全也是程序中必不可少的一环常见的分布式锁： 分布式锁实现实现分布式锁时需要实现的两个基本方法： 获取锁： 互斥：确保只能有一个线程获取锁 非阻塞：尝试一次，成功返回true，失败返回false 释放锁： 手动释放 超时释放：获取锁时添加一个超时时间 核心思路：利用redis 的setNx命令，第一个线程执行了SETNX后，redis 中就有这个key 了，返回了1，如果结果是1，则表示他抢到了锁，那么他去执行业务，然后再删除锁，退出锁逻辑，没有抢到锁的线程，等待一定时间后重试即可 问题：执行EXPIRE指令可以为锁设置过期时间，但是如果在SETNX之后，EXPIRE之前，服务器宕机了，导致没有为锁设置上过期时间，怎么办？ 在SET命令后可以跟上许多参数，其中就包括NX与EX，如果加上了NX，那么此时效果就和SETNX等价。同时在加上EX设置过期时间，将这两条指令结合为一条指令。锁接口 public interface ILock { /** * 尝试获取锁 * @param timeoutSec 锁持有的超时时间，过期后自动释放 * @return true代表获取锁成功; false代表获取锁失败 */ boolean tryLock(long timeoutSec); /** * 释放锁 */ void unlock(); } 实现版本1（使用Redis的SetNX分布式锁来为创建订单业务加锁）public class SimpleRedisLock implements ILock { private String name; private StringRedisTemplate stringRedisTemplate; public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) { this.name = name; this.stringRedisTemplate = stringRedisTemplate; } private static final String KEY_PREFIX = &quot;lock:&quot;; //key为业务相关，值为线程id @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 String threadId = Thread.currentThread().getId(); // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); //由于会拆箱，防止空指针异常 return Boolean.TRUE.equals(success); } @Override public void unlock() { // 释放锁 stringRedisTemplate.delete(KEY_PREFIX + name); } } } 业务代码优化（一人一单，替换Sycronized） @Override public Result seckillVoucher(Long voucherId) { // 1.查询优惠券 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); // 2.判断秒杀是否开始 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { // 尚未开始 return Result.fail(&quot;秒杀尚未开始！&quot;); } // 3.判断秒杀是否已经结束 if (voucher.getEndTime().isBefore(LocalDateTime.now())) { // 尚未开始 return Result.fail(&quot;秒杀已经结束！&quot;); } // 4.判断库存是否充足 if (voucher.getStock() &lt; 1) { // 库存不足 return Result.fail(&quot;库存不足！&quot;); } Long userId = UserHolder.getUser().getId(); //-------------------------------------------------------------------------------- //创建锁对象(新增代码) SimpleRedisLock lock = new SimpleRedisLock(&quot;order:&quot; + userId, stringRedisTemplate); //获取锁对象 boolean isLock = lock.tryLock(1200); //加锁失败 if (!isLock) { return Result.fail(&quot;不允许重复下单&quot;); } try { //获取代理对象(事务) IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy(); return proxy.createVoucherOrder(voucherId); } finally { //释放锁 lock.unlock(); } } 上述方法仍然会存在哪些问题？ 线程1获取锁后由于某个原因阻塞，导致业务还没执行完，锁的过期时间已经到了，因此锁自动释放。此时线程2获取锁并执行业务，而线程1业务恢复，执行业务完毕后仍然会执行释放锁的代码。此时线程3可以获取锁，继续执行业务，导致仍然会出现并发安全问题。 如何解决上述问题？ 在线程释放锁的时候去判断锁标识是否和当前一致，如果一致，才释放锁。 实现版本2（解决线程误删锁问题）需求：修改之前的分布式锁实现，满足：在获取锁时存入线程标示（可以用UUID表示）在释放锁时先获取锁中的线程标示，判断是否与当前线程标示一致 如果一致则释放锁 如果不一致则不释放锁 核心逻辑：在存入锁时，放入自己线程的标识，在删除锁时，判断当前这把锁的标识是不是自己存入的，如果是，则进行删除，如果不是，则不进行删除。 为什么使用UUID，而不是直接使用线程ID？ 由于线程ID在每个JVM内部都是递增的，因此可能会出现不同的服务器中线程ID相同的情况，导致出现冲突。获取锁 private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;; @Override public boolean tryLock(long timeoutSec) { // 获取线程标示 String threadId = ID_PREFIX + Thread.currentThread().getId(); // 获取锁 Boolean success = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS); return Boolean.TRUE.equals(success); } 释放锁 public void unlock() { // 获取线程标示 String threadId = ID_PREFIX + Thread.currentThread().getId(); // 获取锁中的标示 String id = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name); // 判断标示是否一致 if(threadId.equals(id)) { // 释放锁 stringRedisTemplate.delete(KEY_PREFIX + name); } } 上述代码仍然存在什么问题？（极端误删情况） 线程1执行业务，在判断锁标识是否一致，要释放锁之前，发生了阻塞（比如FULL GC）。在阻塞过程中，锁超时释放。此时线程2获取锁并执行，但线程1恢复执行，那么就释放掉线程2的锁，导致仍然出现并发安全问题。问题原因所在：锁标志判断和释放非原子性 实现版本3（Lua脚本将查询锁标志和释放锁变成原子性操作）Redis提供了Lua脚本功能，在一个脚本中编写多条Redis命令，确保多条命令执行时的原子性。Lua是一种编程语言，它的基本语法大家可以参考网站：https://www.runoob.com/lua/lua-tutorial.html，这里重点介绍Redis提供的调用函数，我们可以使用lua去操作redis，又能保证他的原子性，这样就可以实现拿锁比锁删锁是一个原子性动作了，作为Java程序员这一块并不作一个简单要求，并不需要大家过于精通，只需要知道他有什么作用即可。这里重点介绍Redis提供的调用函数，语法如下：redis.call(‘命令名称’, ‘key’, ‘其它参数’, …)例如，我们要执行set name jack，则脚本是这样： # 执行 set name jack redis.call(&#39;set&#39;, &#39;name&#39;, &#39;jack&#39;) 例如，我们要先执行set name Rose，再执行get name，则脚本如下： # 先执行 set name jack redis.call(&#39;set&#39;, &#39;name&#39;, &#39;Rose&#39;) # 再执行 get name local name = redis.call(&#39;get&#39;, &#39;name&#39;) # 返回 return name 通过EVAL命令执行脚本接下来我们来回一下我们释放锁的逻辑：释放锁的业务流程是这样的 1、获取锁中的线程标示 2、判断是否与指定的标示（当前线程标示）一致 3、如果一致则释放锁（删除） 4、如果不一致则什么都不做如果用Lua脚本来表示则是这样的：最终我们操作redis的拿锁比锁删锁的lua脚本就会变成这样 -- 这里的 KEYS[1] 就是锁的key，这里的ARGV[1] 就是当前线程标示 -- 获取锁中的标示，判断是否与当前线程标示一致 if (redis.call(&#39;GET&#39;, KEYS[1]) == ARGV[1]) then -- 一致，则删除锁 return redis.call(&#39;DEL&#39;, KEYS[1]) end -- 不一致，则直接返回 return 0 代码实现 //设置static，在类初始化就加载脚本，不必之后每次使用时重复加载脚本 private static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT; //Redis脚本 static { UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); //设置脚本存放位置 UNLOCK_SCRIPT.setLocation(new ClassPathResource(&quot;unlock.lua&quot;)); //设置脚本返回值类型 UNLOCK_SCRIPT.setResultType(Long.class); } public void unlock() { // 调用lua脚本 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), ID_PREFIX + Thread.currentThread().getId()); } // 经过以上代码改造后，我们就能够实现 拿锁比锁删锁的原子性动作了~ 五、分布式锁（Redission）基于setnx实现的分布式锁存在下面的问题：重入问题：重入问题是指 获得锁的线程可以再次进入到相同的锁的代码块中，可重入锁的意义在于防止死锁，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的synchronized和Lock锁都是可重入的。不可重试：是指目前的分布式只能尝试一次，我们认为合理的情况是：当线程在获得锁失败后，他应该能再次尝试获得锁。超时释放：我们在加锁时增加了过期时间，这样的我们可以防止死锁，但是如果卡顿的时间超长，虽然我们采用了lua表达式防止删锁的时候，误删别人的锁，但是毕竟没有锁住，有安全隐患主从一致性： 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，就会出现死锁问题。 Redisson可重入锁原理Redission可重入锁的设计思想和Reentranlock相似，通过value值来记录当前锁的重入次数。在分布式锁中，采用hash结构来存储锁，大key表示这把锁是否存在，小key指向持有锁的线程，value指向当前被重入的次数。因此当一个线程想持有锁时，它首先判断该锁是否存在，如果不存在，则获取锁，并在hash结构中添加key\\value。如果线程中有另一个方法仍然想获取该锁，则首先判断是否指向同一个线程id，如果是，则vlaue值+1。和Redisson实现可重入锁的逻辑一样，同样是通过哈希+lua脚本来实现的。 Redisson锁重试及超时释放Redisson解决主从一致性（联锁multiLock） 问题引入：Redis的主节点执行了SETNX操作后，该命令还未同步到从节点，主节点就已经宕机。此时Redis通过哨兵模式选取一个新的从节点作为主节点，但是新主节点执行相同的SETNX后返回1，导致有两个线程同时获得了锁，出现并发安全问题。 Redisson是如何解决这个问题的？ 既然主从节点模式下，主从节点会出现数据不一致型的问题。因此Redis设置多个结点，并把每个结点都作为一个独立的结点，即可进行写也可进行读。如果一个线程要获取锁，那么它在多个结点下同时获得锁成功才算成功，只要有一个结点没有成功，那么就会获取锁失败。如果想提高可用性，可以为每个结点，再配置从节点。如果此时有一个主节点宕机，且锁数据还未同步到从节点，当一个线程要获取该锁时，尽管在该从节点设置SETNX返回1，但其他两个结点设置SETNX均返回0，因此即使从节点还未同步锁数据，由于这种机制，仍然保证了多线程下的并发安全问题。 六、秒杀优化对目前优惠券系统进行并发测试（模拟1000个用户同时下单）平均响应时间达到497ms（业务耗时较长） 分析业务执行时间较长的原因 秒杀业务进行各操作是一个串行的执行过程，并且在执行过程中会去数据库中查询或者执行写操作，相对较为耗时。 如何进行优化？（提高并发能力、减轻数据库压力） 将查询优惠券库存、判断库存是否充足以及查询订单、校验一人一单的工作与减库存、创建订单的工作分离开，开启两个独立的线程去分别完成两个工作。将耗时比较短的逻辑判断放入到redis中，比如是否库存足够，比如是否一人一单，这样的操作，只要这种逻辑可以完成，就意味着我们是一定可以下单完成的，我们只需要进行快速的逻辑判断，根本就不用等下单逻辑走完，我们直接给用户返回成功， 再在后台开一个线程，后台线程慢慢的去执行queue里边的消息，这样程序不就超级快了吗？而且也不用担心线程池消耗殆尽的问题，因为这里我们的程序中并没有手动使用任何线程池，当然这里边有两个难点第一个难点是我们怎么在redis中去快速校验一人一单，还有库存判断第二个难点是由于我们校验和tomcat下单是两个线程，那么我们如何知道到底哪个单他最后是否成功，或者是下单完成，为了完成这件事我们在redis操作完之后，我们会将一些信息返回给前端，同时也会把这些信息丢到异步queue中去，后续操作中，可以通过这个id来查询我们tomcat中的下单逻辑是否完成了。实现思路：Redis存储数据的结构库存数据：key: 库存id，value:库存数量一人一单数据：key：库存id，value：保存用户id的set集合。为了在Redis中校验一人一单的逻辑，因此只要一个用户下单成功，就把这个用户id放入到一个set集合中。后续用户想继续下单时，如果判断set中有这个值，就判断已经下过单。当用户下单之后，判断库存是否充足只需要导redis中去根据key找对应的value是否大于0即可，如果不充足，则直接结束，如果充足，继续在redis中判断用户是否可以下单，如果set集合中没有这条数据，说明他可以下单，如果set集合中没有这条记录，则将userId和优惠卷存入到redis中，并且返回0，整个过程需要保证是原子性的，可以使用lua来操作。当以上判断逻辑走完之后，我们可以判断当前redis中返回的结果是否是0 ，如果是0，则表示可以下单，则将之前说的信息存入到到queue中去，然后返回，然后再来个线程异步的下单，前端可以通过返回的订单id来判断是否下单成功。 改进业务1（基于JDK阻塞队列实现秒杀）需求： 新增秒杀优惠券的同时，将优惠券信息保存到Redis中 基于Lua脚本，判断秒杀库存、一人一单，决定用户是否抢购成功 如果抢购成功，将优惠券id和用户id封装后存入阻塞队列 开启线程任务，不断从阻塞队列中获取信息，实现异步下单功能 问题：保存优惠券库存信息到Redis中时，需要设置过期时间吗？ 不需要，优惠券设置了秒杀开始时间与结束时间，当结束时间到了，添加删除优惠券的逻辑。如果删除逻辑失败，由于Redis有数据淘汰策略，由于这个优惠券下架后就不再会被使用，因此当Redis内存达到阈值之后，也会触发淘汰策略把它从Redis中淘汰掉。保存库存信息到Redis中 @Override @Transactional public void addSeckillVoucher(Voucher voucher) { // 保存优惠券 save(voucher); // 保存秒杀信息 SeckillVoucher seckillVoucher = new SeckillVoucher(); seckillVoucher.setVoucherId(voucher.getId()); seckillVoucher.setStock(voucher.getStock()); seckillVoucher.setBeginTime(voucher.getBeginTime()); seckillVoucher.setEndTime(voucher.getEndTime()); seckillVoucherService.save(seckillVoucher); // 保存秒杀库存到Redis中 //SECKILL_STOCK_KEY 这个变量定义在RedisConstans中 //private static final String SECKILL_STOCK_KEY =&quot;seckill:stock:&quot; stringRedisTemplate.opsForValue().set(SECKILL_STOCK_KEY + voucher.getId(), voucher.getStock().toString()); } 完整lua表达式 -- 1.参数列表 -- 1.1.优惠券id local voucherId = ARGV[1] -- 1.2.用户id local userId = ARGV[2] -- 1.3.订单id local orderId = ARGV[3] -- 2.数据key -- 2.1.库存key local stockKey = &#39;seckill:stock:&#39; .. voucherId -- 2.2.订单key local orderKey = &#39;seckill:order:&#39; .. voucherId -- 3.脚本业务 -- 3.1.判断库存是否充足 get stockKey if(tonumber(redis.call(&#39;get&#39;, stockKey)) &lt;= 0) then -- 3.2.库存不足，返回1 return 1 end -- 3.2.判断用户是否下单 SISMEMBER orderKey userId if(redis.call(&#39;sismember&#39;, orderKey, userId) == 1) then -- 3.3.存在，说明是重复下单，返回2 return 2 end -- 3.4.扣库存 incrby stockKey -1 redis.call(&#39;incrby&#39;, stockKey, -1) -- 3.5.下单（保存用户）sadd orderKey userId redis.call(&#39;sadd&#39;, orderKey, userId) -- 3.6.发送消息到队列中， XADD stream.orders * k1 v1 k2 v2 ... redis.call(&#39;xadd&#39;, &#39;stream.orders&#39;, &#39;*&#39;, &#39;userId&#39;, userId, &#39;voucherId&#39;, voucherId, &#39;id&#39;, orderId) return 0 //异步处理线程池 private static final ExecutorService SECKILL_ORDER_EXECUTOR = Executors.newSingleThreadExecutor(); //在类初始化之后执行，因为当这个类初始化好了之后，随时都是有可能要执行的 @PostConstruct private void init() { SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler()); } // 用于线程池处理的任务 // 当初始化完毕后，就会去从对列中去拿信息 private class VoucherOrderHandler implements Runnable{ @Override public void run() { while (true){ try { // 1.获取队列中的订单信息 VoucherOrder voucherOrder = orderTasks.take(); // 2.创建订单 handleVoucherOrder(voucherOrder); } catch (Exception e) { log.error(&quot;处理订单异常&quot;, e); } } } private void handleVoucherOrder(VoucherOrder voucherOrder) { //1.获取用户 Long userId = voucherOrder.getUserId(); // 2.创建锁对象 RLock redisLock = redissonClient.getLock(&quot;lock:order:&quot; + userId); // 3.尝试获取锁 boolean isLock = redisLock.lock(); // 4.判断是否获得锁成功 if (!isLock) { // 获取锁失败，直接返回失败或者重试 log.error(&quot;不允许重复下单！&quot;); return; } try { //注意：由于是spring的事务是放在threadLocal中，此时的是多线程，事务会失效 proxy.createVoucherOrder(voucherOrder); } finally { // 释放锁 redisLock.unlock(); } } //a private BlockingQueue&lt;VoucherOrder&gt; orderTasks =new ArrayBlockingQueue&lt;&gt;(1024 * 1024); @Override public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); long orderId = redisIdWorker.nextId(&quot;order&quot;); // 1.执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString(), String.valueOf(orderId) ); int r = result.intValue(); // 2.判断结果是否为0 if (r != 0) { // 2.1.不为0 ，代表没有购买资格 return Result.fail(r == 1 ? &quot;库存不足&quot; : &quot;不能重复下单&quot;); } VoucherOrder voucherOrder = new VoucherOrder(); // 2.3.订单id long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); // 2.4.用户id voucherOrder.setUserId(userId); // 2.5.代金券id voucherOrder.setVoucherId(voucherId); // 2.6.放入阻塞队列 orderTasks.add(voucherOrder); //3.获取代理对象 proxy = (IVoucherOrderService)AopContext.currentProxy(); //4.返回订单id return Result.ok(orderId); } @Transactional public void createVoucherOrder(VoucherOrder voucherOrder) { Long userId = voucherOrder.getUserId(); // 5.1.查询订单 int count = query().eq(&quot;user_id&quot;, userId).eq(&quot;voucher_id&quot;, voucherOrder.getVoucherId()).count(); // 5.2.判断是否存在 if (count &gt; 0) { // 用户已经购买过了 log.error(&quot;用户已经购买过了&quot;); return ; } // 6.扣减库存 boolean success = seckillVoucherService.update() .setSql(&quot;stock = stock - 1&quot;) // set stock = stock - 1 .eq(&quot;voucher_id&quot;, voucherOrder.getVoucherId()).gt(&quot;stock&quot;, 0) // where id = ? and stock &gt; 0 .update(); if (!success) { // 扣减失败 log.error(&quot;库存不足&quot;); return ; } save(voucherOrder); } 当前的秒杀业务还存在哪些问题？ 内存限制。当前的秒杀任务是基于jdk的阻塞队列实现，这个阻塞队列使用的JVM的内存，如果对阻塞队列不进行限制，那么高并发情况下会有很多订单对象创建并放到阻塞队列中，导致出现内存溢出的风险。因此创建阻塞队列时要为其设置一个长度上限，如果队列存满，那么新的订单就无法添加到队列中。 数据安全（JVM内存没有持久化机制）。如果系统宕机导致存储到队列中的数据丢失，那么用户收到了下单成功消息，但数据库中却没有，导致了出现不一致的问题。 改进业务2（基于Redis消息队列实现秒杀）基于消息队列解决了上述两个问题。首先，消息队列独立于JVM之外，因此没有内存限制。另外，消息队列会对存放其中的消息进行持久化，如果消费者没有对消息进行确认，则消息在消息队列中一直存在。下一次再投递给消费者让消费者继续处理，直到消费者进行确认，才将此消息进行移除。 基于Redis的list实现消息队列Redis的list结构底层是通过双向链表实现的，因此限制生产者从一边push（LPUSH命令），而消费者从另一边pop（RPOP命令），即实现了消息队列的模型。另外，当消息队列中没有消息时，我们希望处于阻塞状态，因此可以使用List的BLPOP、BRPOP命令，当list中无消息时，便会处于阻塞等待的状态。 基于List的消息队列有哪些优缺点？ 优点： 利用Redis存储，不受限于JVM内存上限 基于Redis的持久化机制，数据安全性有保证 可以满足消息有序性 缺点： 无法避免消息丢失（执行完BRPOP之后，就把消息从list中移除，因此从list取出消息后如果出现了异常，消息就会丢失了） 只支持单消费者（拿出消息后就从队列中移除，其他消费者拿不到消息） 基于Redis的PubSub实现消息队列PubSub（发布订阅）是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。SUBSCRIBE channel [channel] ：订阅一个或多个频道 PUBLISH channel msg ：向一个频道发送消息 PSUBSCRIBE pattern[pattern] ：订阅与pattern格式匹配的所有频道基于PubSub的消息队列有哪些优缺点？优点： 采用发布订阅模型，支持多生产、多消费 缺点： 不支持数据持久化（Redis的数据是有持久化机制，但PubSub是另一种发布订阅模型，并不支持数据持久化） 无法避免消息丢失 消息堆积有上限，超出时数据丢失（消费者有缓存区域，如果处理一个消息时时间过久，其他消息到达后存储到缓存区中，缓存区满了后消息就会丢失） 基于Stream的消息队列Stream 是 Redis 5.0 引入的一种新数据类型（支持数据持久化），可以实现一个功能非常完善的消息队列。 单消费模式 命令 介绍 XADD 向队列中添加消息 XREAD 读取队列中的消息 XLEN 读取队列中消息的长度 发送消息的命令：例如：读取消息的方式之一：XREAD例如，使用XREAD读取第一个消息：XREAD阻塞方式，读取最新的消息：添加到Strem队列中的消息可以被多个消费者读取，不会出现其他消费者读了之后，消息就从队列中丢失掉的情况。在业务开发中，我们可以循环的调用XREAD阻塞方式来查询最新消息，从而实现持续监听队列的效果，伪代码如下 上述的队列实现存在什么问题？ 消息漏读。我们指定起始ID为$时，代表读取最新的消息，如果我们处理一条消息的过程中，又有超过1条以上的消息到达队列，则下次获取时也只能获取到最新的一条，会出现漏读消息的问题。STREAM类型消息队列的XREAD命令特点： 消息可回溯（消息添加到队列后不会消失，可回看） 一个消息可以被多个消费者读取 可以阻塞读取 有消息漏读的风险 消费者组 单消费和消费者组模式有什么区别？ 消费者组是将多个消费者划分到一个组中，监听同一个队列。用来解决消息漏读的问题。特点： 消息分流。队列中的消息会被分到组内的不同消费者，加快了消息处理的速度，避免出现消息堆积的情况。 消息标示。消费者组中维护了一个记录最后一个被处理的消息的标识，通过该标识，可以确保每个消息都会被消费， 避免出现消息漏读的情况。 消息确认。消费者获取消息之后，消息会处于pending状态，并且处于pending状态的消息会存入到pending-list中。如果消息处理完毕，需要XACK确认消息，标记消息已被处理，并会从pendinglist中移除。该机制确保了消息至少会被消费一次。如果Redis宕机，在恢复后可以到pending-list中找到还未完成处理的消息，继续处理。 基本命令创建消费者组 XGROUP CREAT key groupName ID [MKSTREAM] 删除指定的消费者组 XGROUP DESTORY key groupName 给指定的消费者组添加消费者 XGROUP CREATECONSUMER key groupname consumername 删除消费者组中的指定消费者 XGROUP DELCONSUMER key groupname consumername 从消费者组读取消息 XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...] group：消费组名称 consumer：消费者名称，如果消费者不存在，会自动创建一个消费者 count：本次查询的最大数量 BLOCK milliseconds：当没有消息时最长等待时间 NOACK：无需手动ACK，消息投递到消费者后会自动确认 STREAMS key：指定队列名称 ID：获取消息的起始ID： “&gt;”：从下一个未消费的消息开始（正常情况下读未消费的消息） 其它：根据指定id从pending-list中获取已消费但未确认的消息，例如0，是从pending-list中的第一个消息开始（出现异常时，从pending-list中读取已消费但未处理成功的消息） 确认消息 XACK key group ID [ID ...] 消费者组监听消息思路（确保消息至少会被消费一次）：正常情况下，由消费者组来监听队列中未被消费的消息；如果监听过程中出现了异常，则在捕获异常的处理逻辑中去处理已消费但还未确认的消息，当这些未确认的消息处理完毕后，再监听未被消费的消息。代码实现STREAM类型消息队列的XREADGROUP命令特点： 消息可回溯 可以多消费者争抢消息，加快消费速度 可以阻塞读取 没有消息漏读的风险（有最后一次被处理消息的标识，每次读取时，可从上一次消费消息后的一条消息读取） 有消息确认机制，保证消息至少被消费一次 使用Stream队列还存在什么缺点？ 依赖于Redis持久化，仍然存在消息丢失的风险 Stream只支持消费者确认，并不支持生产者确认，因此如果生产者消息丢失，还需要考虑如何解决 代码实现具体思路：在redis里进行库存判断+一人一单判断后，将库存id、用户id、订单id发送到消息队列中，完成后判断是否可以下单成功，如果可以，则直接返回数据。然后开启另外一个线程完成异步下单的功能。在进行异步下单时，开启的线程一直监听队列中的消息。如果监听到消息，则执行处理，并返回对该消息的确认。如果发生了异常，则要处理已消费但未确认的消息。lua脚本 -- 1.参数列表 -- 1.1.优惠券id local voucherId = ARGV[1] -- 1.2.用户id local userId = ARGV[2] -- 1.3.订单id local orderId = ARGV[3] -- 2.数据key -- 2.1.库存key local stockKey = &#39;seckill:stock:&#39; .. voucherId -- 2.2.订单key local orderKey = &#39;seckill:order:&#39; .. voucherId -- 3.脚本业务 -- 3.1.判断库存是否充足 get stockKey if(tonumber(redis.call(&#39;get&#39;, stockKey)) &lt;= 0) then -- 3.2.库存不足，返回1 return 1 end -- 3.2.判断用户是否下单 SISMEMBER orderKey userId if(redis.call(&#39;sismember&#39;, orderKey, userId) == 1) then -- 3.3.存在，说明是重复下单，返回2 return 2 end -- 3.4.扣库存 incrby stockKey -1 redis.call(&#39;incrby&#39;, stockKey, -1) -- 3.5.下单（保存用户）sadd orderKey userId redis.call(&#39;sadd&#39;, orderKey, userId) -- 3.6.发送消息到队列中， XADD stream.orders * k1 v1 k2 v2 ... redis.call(&#39;xadd&#39;, &#39;stream.orders&#39;, &#39;*&#39;, &#39;userId&#39;, userId, &#39;voucherId&#39;, voucherId, &#39;id&#39;, orderId) return 0 VoucherOrderServiceImpl private class VoucherOrderHandler implements Runnable { @Override public void run() { while (true) { try { // 1.获取消息队列中的订单信息 XREADGROUP GROUP g1 c1 COUNT 1 BLOCK 2000 STREAMS s1 &gt; List&lt;MapRecord&lt;String, Object, Object&gt;&gt; list = stringRedisTemplate.opsForStream().read( Consumer.from(&quot;g1&quot;, &quot;c1&quot;), StreamReadOptions.empty().count(1).block(Duration.ofSeconds(2)), StreamOffset.create(&quot;stream.orders&quot;, ReadOffset.lastConsumed()) ); // 2.判断订单信息是否为空 if (list == null || list.isEmpty()) { // 如果为null，说明没有消息，继续下一次循环 continue; } // 解析数据 MapRecord&lt;String, Object, Object&gt; record = list.get(0); Map&lt;Object, Object&gt; value = record.getValue(); VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true); // 3.创建订单 createVoucherOrder(voucherOrder); // 4.确认消息 XACK stringRedisTemplate.opsForStream().acknowledge(&quot;s1&quot;, &quot;g1&quot;, record.getId()); } catch (Exception e) { log.error(&quot;处理订单异常&quot;, e); //处理异常消息 handlePendingList(); } } } private void handlePendingList() { while (true) { try { // 1.获取pending-list中的订单信息 XREADGROUP GROUP g1 c1 COUNT 1 BLOCK 2000 STREAMS s1 0 List&lt;MapRecord&lt;String, Object, Object&gt;&gt; list = stringRedisTemplate.opsForStream().read( Consumer.from(&quot;g1&quot;, &quot;c1&quot;), StreamReadOptions.empty().count(1), StreamOffset.create(&quot;stream.orders&quot;, ReadOffset.from(&quot;0&quot;)) ); // 2.判断订单信息是否为空 if (list == null || list.isEmpty()) { // 如果为null，说明没有异常消息，结束循环 break; } // 解析数据 MapRecord&lt;String, Object, Object&gt; record = list.get(0); Map&lt;Object, Object&gt; value = record.getValue(); VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true); // 3.创建订单 createVoucherOrder(voucherOrder); // 4.确认消息 XACK stringRedisTemplate.opsForStream().acknowledge(&quot;s1&quot;, &quot;g1&quot;, record.getId()); } catch (Exception e) { log.error(&quot;处理pendding订单异常&quot;, e); try{ Thread.sleep(20); }catch(Exception e){ e.printStackTrace(); } } } } public Result seckillVoucher(Long voucherId) { Long userId = UserHolder.getUser().getId(); long orderId = redisIdWorker.nextId(&quot;order&quot;); // 1.执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString(), String.valueOf(orderId) ); int r = result.intValue(); // 2.判断结果是否为0 if (r != 0) { // 2.1.不为0 ，代表没有购买资格 return Result.fail(r == 1 ? &quot;库存不足&quot; : &quot;不能重复下单&quot;); } // 3.返回订单id return Result.ok(orderId); } } 并发测试 七、达人探店数据表tb_blog（探店笔记表）tb_blog_comments 接口 介绍 返回值 /blog 发布探店笔记接口 /blog/{id} 查看探店笔记接口 笔记信息+用户信息 /blog/like/id 点赞探店笔记接口 /blog/likes/{id} 点赞探店笔记列表接口 发布探店笔记上传照片和发布图文是两个不同的接口，用户需要上传图片时调用上传图片的接口，然后接口会返回图片的名称信息。后面调用发布笔记的接口时，会把图片的名称传到接口中。 查看探店笔记 点赞探店笔记 实现1@GetMapping(&quot;/likes/{id}&quot;) public Result queryBlogLikes(@PathVariable(&quot;id&quot;) Long id) { //修改点赞数量 blogService.update().setSql(&quot;liked = liked +1 &quot;).eq(&quot;id&quot;,id).update(); return Result.ok(); } 问题：没有对点赞量进行限制，一个用户可以为同一篇探店笔记点多个赞 实现2需求： 同一个用户只能点赞一次，再次点击则取消点赞 如果当前用户已经点赞，则点赞按钮高亮显示（前端已实现，判断字段Blog类的isLike属性） 实现步骤： 给Blog类中添加一个isLike字段，标示是否被当前用户点赞 修改点赞功能，利用Redis的set集合判断是否点赞过，未点赞过则点赞数+1，已点赞过则点赞数-1 修改根据id查询Blog的业务，判断当前登录用户是否点赞过，赋值给isLike字段 修改分页查询Blog业务，判断当前登录用户是否点赞过，赋值给isLike字段 判断用户是否点过赞的思路有哪些？ 建立一个点赞表，里面包括Blog ID以及User ID，当要判断当前用户是否点过赞，则根据Blog ID和User ID到数据库中去查询。（数据库压力大、直接访问数据库，导致性能低） 使用Redis的set集合 代码实现： 在Blog中添加isLike字段 @TableField(exist = false) private Boolean isLike; 修改代码 @Override public Result likeBlog(Long id){ // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); // 2.判断当前登录用户是否已经点赞 String key = BLOG_LIKED_KEY + id; Boolean isMember = stringRedisTemplate.opsForSet().isMember(key, userId.toString()); if(BooleanUtil.isFalse(isMember)){ //3.如果未点赞，可以点赞 //3.1 数据库点赞数+1 boolean isSuccess = update().setSql(&quot;liked = liked + 1&quot;).eq(&quot;id&quot;, id).update(); //3.2 保存用户到Redis的set集合 if(isSuccess){ stringRedisTemplate.opsForSet().add(key,userId.toString()); } }else{ //4.如果已点赞，取消点赞 //4.1 数据库点赞数-1 boolean isSuccess = update().setSql(&quot;liked = liked - 1&quot;).eq(&quot;id&quot;, id).update(); //4.2 把用户从Redis的set集合移除 if(isSuccess){ stringRedisTemplate.opsForSet().remove(key,userId.toString()); } } 点赞排行榜(越早越靠前) 思考：点赞的信息都保存在了Redis中，那Redis宕机了，点赞信息丢失了怎么办？（Redis数据持久化） 可以隔一定时间就将Redis中的数据持久化到磁盘文件中，防止Redis宕机数据全部丢失。Redis中提供save以及bgsave指令来生成RDB文件，二者的主要区别是生成RDB文件的任务是否是交由主线程来执行。 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞； 另外，还可以通过在配置文件中配置，让Redis每个一段时间自动执行一次bgsave指令 save 900 1 save 300 10 save 60 10000 // 只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是： // 900 秒之内，对数据库进行了至少 1 次修改； // 300 秒之内，对数据库进行了至少 10 次修改； // 60 秒之内，对数据库进行了至少 10000 次修改。 通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。 对于Redis中可以用做点赞列表的数据类型分析List底层是链表，因此如果向List中通过RPUSH添加点赞用户，通过LINDEX获取列表头部元素，就实现了点赞列表排序功能。但LIst元素不保证唯一，且由于底层是链表，因此只能通过索引获取元素。如果想通过元素进行查找，那需要遍历链表。因此List并不适合用作点赞列表。Set和SortedSet底层是哈希表，它们可以根据元素来快速定位到指定位置。由于SortedSet会为每一个元素关联一个分数，因此如果要实现排序功能的话，需要使用SortedSet。由于业务中想显示点赞时间最靠前的五位用户，因此可以用时间戳作为分数（时间戳天然升序）。 指令 描述 ZSCORE key member 获取指定元素的score，元素存在返回score，元素不存在返回nil ZRANGE key min max 返回SortedSet中指定区间内的成员，其中成员按从小到大排序 修改业务代码1点赞代码（将Set替换为ZSet，由于ZSet中没有isMember指令，因此需要使用ZSCORE指令来判断用户是否存在） @Override public Result likeBlog(Long id) { // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); // 2.判断当前登录用户是否已经点赞 String key = BLOG_LIKED_KEY + id; Double score = stringRedisTemplate.opsForZSet().score(key, userId.toString()); if (score == null) { // 3.如果未点赞，可以点赞 // 3.1.数据库点赞数 + 1 boolean isSuccess = update().setSql(&quot;liked = liked + 1&quot;).eq(&quot;id&quot;, id).update(); // 3.2.保存用户到Redis的set集合 zadd key value score if (isSuccess) { stringRedisTemplate.opsForZSet().add(key, userId.toString(), System.currentTimeMillis()); } } else { // 4.如果已点赞，取消点赞 // 4.1.数据库点赞数 -1 boolean isSuccess = update().setSql(&quot;liked = liked - 1&quot;).eq(&quot;id&quot;, id).update(); // 4.2.把用户从Redis的set集合移除 if (isSuccess) { stringRedisTemplate.opsForZSet().remove(key, userId.toString()); } } return Result.ok(); } private void isBlogLiked(Blog blog) { // 1.获取登录用户 UserDTO user = UserHolder.getUser(); if (user == null) { // 用户未登录，无需查询是否点赞 return; } Long userId = user.getId(); // 2.判断当前登录用户是否已经点赞 String key = &quot;blog:liked:&quot; + blog.getId(); Double score = stringRedisTemplate.opsForZSet().score(key, userId.toString()); blog.setIsLike(score != null); } 点赞列表查询代码BlogController @GetMapping(&quot;/likes/{id}&quot;) public Result queryBlogLikes(@PathVariable(&quot;id&quot;) Long id) { return blogService.queryBlogLikes(id); } BlogService @Override public Result queryBlogLikes(Long id) { String key = BLOG_LIKED_KEY + id; // 1.查询top5的点赞用户 zrange key 0 4 Set&lt;String&gt; top5 = stringRedisTemplate.opsForZSet().range(key, 0, 4); if (top5 == null || top5.isEmpty()) { return Result.ok(Collections.emptyList()); } // 2.解析出其中的用户id List&lt;Long&gt; ids = top5.stream().map(Long::valueOf).collect(Collectors.toList()); //select ... from tb_user where id in (?,?) List&lt;UserDTO&gt; userDTOS = userService.listByIds(ids) .stream() .map(user -&gt; BeanUtil.copyProperties(user, UserDTO.class)) .collect(Collectors.toList()); // 4.返回 return Result.ok(userDTOS); } 测试(点赞并未如预期的按照时间戳从小到大排列)预想结果：按时间戳由小到大进行排列，先点赞的在前，后点赞的在后，即点赞后蓝色头像排在黄色头像之后。分析原因： **查看接口返回的响应信息 **返回结果的顺序出现错误，当前登录用户为小鱼同学，小鱼同学点赞后应排在第二位，但实际上却排在了第一位。 **分析使用Mybatis进行查询时传入的参数是否正确 传入的参数先5再1符合预期 **检查SQL语句（这里出现错误） 使用in查询，传入的顺序是5,1，但查出的顺序是1,5。 **解决：通过Order by filed 通过手动指定id的顺序来对其进行限制 修改业务代码2@Override public Result queryBlogLikes(Long id) { String key = BLOG_LIKED_KEY + id; // 1.查询top5的点赞用户 zrange key 0 4 Set&lt;String&gt; top5 = stringRedisTemplate.opsForZSet().range(key, 0, 4); if (top5 == null || top5.isEmpty()) { return Result.ok(Collections.emptyList()); } // 2.解析出其中的用户id List&lt;Long&gt; ids = top5.stream().map(Long::valueOf).collect(Collectors.toList()); String idStr = StrUtil.join(&quot;,&quot;, ids); // 3.根据用户id查询用户 WHERE id IN ( 5 , 1 ) ORDER BY FIELD(id, 5, 1) List&lt;UserDTO&gt; userDTOS = userService.query() .in(&quot;id&quot;, ids).last(&quot;ORDER BY FIELD(id,&quot; + idStr + &quot;)&quot;).list() .stream() .map(user -&gt; BeanUtil.copyProperties(user, UserDTO.class)) .collect(Collectors.toList()); // 4.返回 return Result.ok(userDTOS); } 结果 八、好友关注接口 接口 描述 参数 响应 /follow/1/true 关注/取关用户 1：被关注用户id true：关注 false：取消关注 /follow/or/not/1 是否关注用户 1：被关注用户id true：未关注要进行关注 false：已关注 数据表 关注和取关首先当点进博客时首先会判断当前登录用户是否关注了博主查询结果未关注，则前端按键会显示关注按钮点击发起关注请求时，传参为true，表示要进行关注 代码实现FollowController //关注 @PutMapping(&quot;/{id}/{isFollow}&quot;) public Result follow(@PathVariable(&quot;id&quot;) Long followUserId, @PathVariable(&quot;isFollow&quot;) Boolean isFollow) { return followService.follow(followUserId, isFollow); } //取消关注 @GetMapping(&quot;/or/not/{id}&quot;) public Result isFollow(@PathVariable(&quot;id&quot;) Long followUserId) { return followService.isFollow(followUserId); } FollowService // 取消关注service @Override public Result isFollow(Long followUserId) { // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); // 2.查询是否关注 select count(*) from tb_follow where user_id = ? and follow_user_id = ? Integer count = query().eq(&quot;user_id&quot;, userId).eq(&quot;follow_user_id&quot;, followUserId).count(); // 3.判断 return Result.ok(count &gt; 0); } // 关注service @Override public Result follow(Long followUserId, Boolean isFollow) { // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); String key = &quot;follows:&quot; + userId; // 1.判断到底是关注还是取关 if (isFollow) { // 2.关注，新增数据 Follow follow = new Follow(); follow.setUserId(userId); follow.setFollowUserId(followUserId); boolean isSuccess = save(follow); } else { // 3.取关，删除 delete from tb_follow where user_id = ? and follow_user_id = ? remove(new QueryWrapper&lt;Follow&gt;() .eq(&quot;user_id&quot;, userId).eq(&quot;follow_user_id&quot;, followUserId)); } return Result.ok(); } 共同关注分析：共同关注即找到了博主和登录用户关注列表的交集，在Redis中的set集合中有SINTER指令来得到多个key的交集。业务代码改进：由于之前在关注和取消时，只把数据保存到了数据库中，因此现在需要改进业务代码，把用户及用户关注以key（当前用户id），value(set)的形式保存至Redis中。 @Override public Result follow(Long followUserId, Boolean isFollow) { // 1.获取登录用户 Long userId = UserHolder.getUser().getId(); String key = &quot;follows:&quot; + userId; // 1.判断到底是关注还是取关 if (isFollow) { // 2.关注，新增数据 Follow follow = new Follow(); follow.setUserId(userId); follow.setFollowUserId(followUserId); boolean isSuccess = save(follow); if (isSuccess) { // 把关注用户的id，放入redis的set集合 sadd userId followerUserId stringRedisTemplate.opsForSet().add(key, followUserId.toString()); } } else { // 3.取关，删除 delete from tb_follow where user_id = ? and follow_user_id = ? boolean isSuccess = remove(new QueryWrapper&lt;Follow&gt;() .eq(&quot;user_id&quot;, userId).eq(&quot;follow_user_id&quot;, followUserId)); if (isSuccess) { // 把关注用户的id从Redis集合中移除 stringRedisTemplate.opsForSet().remove(key, followUserId.toString()); } } return Result.ok(); } 获取多个set集合的交集 @Override public Result followCommons(Long id) { // 1.获取当前用户 Long userId = UserHolder.getUser().getId(); String key = &quot;follows:&quot; + userId; // 2.求交集 String key2 = &quot;follows:&quot; + id; Set&lt;String&gt; intersect = stringRedisTemplate.opsForSet().intersect(key, key2); if (intersect == null || intersect.isEmpty()) { // 无交集 return Result.ok(Collections.emptyList()); } // 3.解析id集合 List&lt;Long&gt; ids = intersect.stream().map(Long::valueOf).collect(Collectors.toList()); // 4.查询用户 List&lt;UserDTO&gt; users = userService.listByIds(ids) .stream() .map(user -&gt; BeanUtil.copyProperties(user, UserDTO.class)) .collect(Collectors.toList()); return Result.ok(users); } 效果展示 关注推送（Feed流）Feed流的实现有两种模式： Timeline：不做内容筛选，简单的按照内容发布时间排序，常用于好友或关注。例如朋友圈优点：信息全面，不会有缺失。并且实现也相对简单缺点：信息噪音较多，用户不一定感兴趣，内容获取效率低 智能排序：利用智能算法屏蔽掉违规的、用户不感兴趣的内容。推送用户感兴趣信息来吸引用户优点：投喂用户感兴趣信息，用户粘度很高，容易沉迷缺点：如果算法不精准，可能起到反作用 本项目中的个人页面，是基于关注的好友来做Feed流，因此用Timeline的模式。该模式的实现方案有三种 **拉模式 每个用户发了Blog之后，都会把消息存入到其对应的发件箱中。粉丝只有在浏览时才会把关注博主的Blog信息推送到自己的收件箱中。 优点：节约空间，因为赵六在读信息时，并没有重复读取，而且读取完之后可以把他的收件箱进行清除。 缺点：延迟，当用户读取数据时才去关注的人里边去读取数据，假设用户关注了大量的用户，那么此时就会拉取海量的内容，对服务器压力巨大。 推模式用户没有发件箱，只有收件箱。当用户发了消息之后，将消息推送到所有粉丝的收件箱中。优点：时效快，不用临时拉取。缺点：内存压力大，假设一个大V写信息，很多人关注他， 就会写很多数据到每个粉丝的收件箱中。 **推拉结合 **推拉模式将用户分为大V和普通用户，将粉丝分为活跃粉丝和普通粉丝。对于普通用户来说，由于其粉丝数量较少，因此使用推模式，在发送消息时并没有使用发件箱，而是将消息直接发送到每个粉丝的收件箱中。对于大V用户来说，其粉丝体量较大，但粉丝中绝大多数为普通粉丝，活跃粉丝占比较少。因此对于活跃粉丝采取推模式，而对于不经常上线的普通粉丝使用拉模式，只有粉丝上线需要浏览消息时才从大V的发件箱中拉去消息到粉丝的收件箱中。 业务分析需求： 修改新增探店笔记的业务，在保存blog到数据库的同时，推送到粉丝的收件箱 收件箱满足可以根据时间戳排序，必须用Redis的数据结构实现 查询收件箱数据时，可以实现分页查询 要求推送到收件箱的blog信息按照时间戳排序，那么Redis中的List和ZSet都能满足这个需求。要求查询收件箱数据时，可以实现分页查询。List底层是链表，因此是有角标的。可以通过List中的LRANGE key start top来获取指定范围内的元素。而ZSet虽然没有角标，但是在ZSet中有排名，因此可以通过ZRANGE key start top来获取指定范围内的元素。那该如何选择呢？Feed流的分页问题Feed流的数据会不断更新，由于我们每次希望读取最新数据，从最新数据读取时，数据的角标也在变化，这会导致读取到重复的数据。因此不能采用传统的分页模式。模拟按脚标查询，读取到了重复数据解决设置一个last记录上一次分页的位置总结List 只支持角标查询，一旦插入了新数据，角标就会发生变化，因此不支持滚动分页。如果ZSet按照排名查询（角标），和List一样也不支持滚动分页。但是ZSet还支持按score值的范围进行查询，将score按从大到小进行排列，每次查询都记录最小时间戳，下次查询时找到比这个时间戳更小的，从而实现滚动分页。通过ZRANGEBYSCORE key max min实现 思考：通过ZRANGEBYSCORE key max min实现会出现什么问题？ ZRANGEBYSCORE z1 1000 0 withscores limit 0 3，它表示在进行查询时从z1的set中查询从1000开始的第1条记录（包含）的三条数据ZRANGEBYSCORE z1 6 0 withscores limit 1 3，它表示在进行查询时从z1的set中查询从6开始的第一条记录后（不包含）三条数据。因此如果多个用户分数相同，如果固定offset为1，它只会略过一条分数为6的记录，因此还是会出现重复问题。为了解决这个问题，除了需要记录上一次分页的最小值分数外，还需要记录有多少个最小值分数，并把它作为limit的offset参数。 代码实现（Feed流+Sortedset滚动分页）改造代码，当用户保存Blog后，将Blog信息推送到粉丝的收件箱中 @Override public Result saveBlog(Blog blog) { // 1.获取登录用户 UserDTO user = UserHolder.getUser(); blog.setUserId(user.getId()); // 2.保存探店笔记 boolean isSuccess = save(blog); if(!isSuccess){ return Result.fail(&quot;新增笔记失败!&quot;); } // 3.查询笔记作者的所有粉丝 select * from tb_follow where follow_user_id = ? List&lt;Follow&gt; follows = followService.query().eq(&quot;follow_user_id&quot;, user.getId()).list(); // 4.推送笔记id给所有粉丝 for (Follow follow : follows) { // 4.1.获取粉丝id Long userId = follow.getUserId(); // 4.2.推送 String key = FEED_KEY + userId; stringRedisTemplate.opsForZSet().add(key, blog.getId().toString(), System.currentTimeMillis()); } // 5.返回id return Result.ok(blog.getId()); } 从收件箱中分页查询推送Blog信息 @Data public class ScrollResult { private List&lt;?&gt; list; private Long minTime; private Integer offset; } @GetMapping(&quot;/of/follow&quot;) public Result queryBlogOfFollow( @RequestParam(&quot;lastId&quot;) Long max, @RequestParam(value = &quot;offset&quot;, defaultValue = &quot;0&quot;) Integer offset){ return blogService.queryBlogOfFollow(max, offset); } @Override public Result queryBlogOfFollow(Long max, Integer offset) { // 1.获取当前用户 Long userId = UserHolder.getUser().getId(); // 2.查询收件箱 ZREVRANGEBYSCORE key Max Min LIMIT offset count String key = FEED_KEY + userId; Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; typedTuples = stringRedisTemplate.opsForZSet() .reverseRangeByScoreWithScores(key, 0, max, offset, 2); // 3.非空判断 if (typedTuples == null || typedTuples.isEmpty()) { return Result.ok(); } // 4.解析数据：blogId、minTime（时间戳）、offset List&lt;Long&gt; ids = new ArrayList&lt;&gt;(typedTuples.size()); long minTime = 0; // 2 int os = 1; // 2 for (ZSetOperations.TypedTuple&lt;String&gt; tuple : typedTuples) { // 5 4 4 2 2 // 4.1.获取id ids.add(Long.valueOf(tuple.getValue())); // 4.2.获取分数(时间戳） long time = tuple.getScore().longValue(); if(time == minTime){ os++; }else{ minTime = time; os = 1; } } os = minTime == max ? os : os + offset; // 5.根据id查询blog String idStr = StrUtil.join(&quot;,&quot;, ids); List&lt;Blog&gt; blogs = query().in(&quot;id&quot;, ids).last(&quot;ORDER BY FIELD(id,&quot; + idStr + &quot;)&quot;).list(); for (Blog blog : blogs) { // 5.1.查询blog有关的用户 queryBlogUser(blog); // 5.2.查询blog是否被点赞 isBlogLiked(blog); } // 6.封装并返回 ScrollResult r = new ScrollResult(); r.setList(blogs); r.setOffset(os); r.setMinTime(minTime); return Result.ok(r); } 九、附近商户GEO介绍GEO就是Geolocation的简写形式，代表地理坐标。Redis在3.2版本中加入了对GEO的支持，允许存储地理坐标信息，帮助我们根据经纬度来检索数据。常见的命令有： GEOADD：添加一个地理空间信息，包含：经度（longitude）、纬度（latitude）、值（member） GEODIST：计算指定的两个点之间的距离并返回 GEOHASH：将指定member的坐标转为hash字符串形式并返回 GEOPOS：返回指定member的坐标 GEORADIUS：指定圆心、半径，找到该圆内包含的所有member，并按照与圆心之间的距离排序后返回。6.以后已废弃 GEOSEARCH：在指定范围内搜索member，并按照与指定点之间的距离排序后返回。范围可以是圆形或矩形。6.2.新功能 GEOSEARCHSTORE：与GEOSEARCH功能一致，不过可以把结果存储到一个指定的key。 6.2.新功能 业务介绍商户数据表请求信息保存在Redis中的数据格式GEO底层是Zset数据结构，其中会把member作为value，把经纬度计算出一个值作为score存入到Redis的GEO中由于在首页中，我们会点进去一个具体类型，在这个具体类型中查看距离由小到大排序的商铺信息。为了按照type来对数据进行筛选，因此使用类型作为key，商户id作为member，往GEO中存入信息。之后在进行查询时，就直接获取某一个类型对应的GEO数据即可。将商铺信息预热到Redis中 @Test void loadShopData() { // 1.查询店铺信息 List&lt;Shop&gt; list = shopService.list(); // 2.把店铺分组，按照typeId分组，typeId一致的放到一个集合 Map&lt;Long, List&lt;Shop&gt;&gt; map = list.stream().collect(Collectors.groupingBy(Shop::getTypeId)); // 3.分批完成写入Redis for (Map.Entry&lt;Long, List&lt;Shop&gt;&gt; entry : map.entrySet()) { // 3.1.获取类型id Long typeId = entry.getKey(); String key = SHOP_GEO_KEY + typeId; // 3.2.获取同类型的店铺的集合 List&lt;Shop&gt; value = entry.getValue(); List&lt;RedisGeoCommands.GeoLocation&lt;String&gt;&gt; locations = new ArrayList&lt;&gt;(value.size()); // 3.3.写入redis GEOADD key 经度 纬度 member for (Shop shop : value) { // stringRedisTemplate.opsForGeo().add(key, new Point(shop.getX(), shop.getY()), shop.getId().toString()); locations.add(new RedisGeoCommands.GeoLocation&lt;&gt;( shop.getId().toString(), new Point(shop.getX(), shop.getY()) )); } stringRedisTemplate.opsForGeo().add(key, locations); } } @GetMapping(&quot;/of/type&quot;) public Result queryShopByType( @RequestParam(&quot;typeId&quot;) Integer typeId, @RequestParam(value = &quot;current&quot;, defaultValue = &quot;1&quot;) Integer current, @RequestParam(value = &quot;x&quot;, required = false) Double x, @RequestParam(value = &quot;y&quot;, required = false) Double y ) { return shopService.queryShopByType(typeId, current, x, y); } @Override public Result queryShopByType(Integer typeId, Integer current, Double x, Double y) { // 1.判断是否需要根据坐标查询 if (x == null || y == null) { // 不需要坐标查询，按数据库查询 Page&lt;Shop&gt; page = query() .eq(&quot;type_id&quot;, typeId) .page(new Page&lt;&gt;(current, SystemConstants.DEFAULT_PAGE_SIZE)); // 返回数据 return Result.ok(page.getRecords()); } // 2.计算分页参数 int from = (current - 1) * SystemConstants.DEFAULT_PAGE_SIZE; int end = current * SystemConstants.DEFAULT_PAGE_SIZE; // 3.查询redis、按照距离排序、分页。结果：shopId、distance String key = SHOP_GEO_KEY + typeId; GeoResults&lt;RedisGeoCommands.GeoLocation&lt;String&gt;&gt; results = stringRedisTemplate.opsForGeo() // GEOSEARCH key BYLONLAT x y BYRADIUS 10 WITHDISTANCE .search( key, GeoReference.fromCoordinate(x, y), new Distance(5000), RedisGeoCommands.GeoSearchCommandArgs.newGeoSearchArgs().includeDistance().limit(end) ); // 4.解析出id if (results == null) { return Result.ok(Collections.emptyList()); } List&lt;GeoResult&lt;RedisGeoCommands.GeoLocation&lt;String&gt;&gt;&gt; list = results.getContent(); if (list.size() &lt;= from) { // 没有下一页了，结束 return Result.ok(Collections.emptyList()); } // 4.1.截取 from ~ end的部分 List&lt;Long&gt; ids = new ArrayList&lt;&gt;(list.size()); Map&lt;String, Distance&gt; distanceMap = new HashMap&lt;&gt;(list.size()); list.stream().skip(from).forEach(result -&gt; { // 4.2.获取店铺id String shopIdStr = result.getContent().getName(); ids.add(Long.valueOf(shopIdStr)); // 4.3.获取距离 Distance distance = result.getDistance(); distanceMap.put(shopIdStr, distance); }); // 5.根据id查询Shop String idStr = StrUtil.join(&quot;,&quot;, ids); List&lt;Shop&gt; shops = query().in(&quot;id&quot;, ids).last(&quot;ORDER BY FIELD(id,&quot; + idStr + &quot;)&quot;).list(); for (Shop shop : shops) { shop.setDistance(distanceMap.get(shop.getId().toString()).getValue()); } // 6.返回 return Result.ok(shops); }","categories":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}],"tags":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/tags/项目/"}],"keywords":[{"name":"项目","slug":"项目","permalink":"https://xingxin-99.github.io/categories/项目/"}]},{"title":"Java","slug":"Java","date":"2023-06-24T14:06:19.000Z","updated":"2023-08-25T07:19:09.402Z","comments":true,"path":"2023/06/24/Java/","link":"","permalink":"https://xingxin-99.github.io/2023/06/24/Java/","excerpt":"","text":"Java","categories":[{"name":"Java","slug":"Java","permalink":"https://xingxin-99.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://xingxin-99.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://xingxin-99.github.io/categories/Java/"}]},{"title":"Mybatis","slug":"Mybatis","date":"2023-05-25T08:18:45.000Z","updated":"2023-08-26T10:54:11.949Z","comments":true,"path":"2023/05/25/Mybatis/","link":"","permalink":"https://xingxin-99.github.io/2023/05/25/Mybatis/","excerpt":"","text":"一、Mybatis概述 二、Mybatis入门程序maven中为什么放在resource目录下的资源，等于放在类的根路径下在 Maven 项目中，src/main/resources 目录下的资源文件会被打包进生成的 Jar 或 War 包中，并放在类路径的根目录下。这是因为 Maven 在构建项目时会把 src/main/resources 目录作为类路径的一部分，所以所有放在这个目录下的文件都会被打包进去。在 Java 项目中，类路径指的是 JVM 用来搜索类和资源文件的路径。类路径的根目录是指能够直接被 JVM 搜索到的目录，这个目录下的文件都可以直接用 ClassLoader 加载。在 Maven 项目中，src/main/resources 目录中的文件就是放在这个根目录下的。因此，如果我们把某个资源文件放在 src/main/resources 目录下，它就相当于放在了类路径的根目录下，可以直接通过 ClassLoader 加载，无需指定路径。这也是 Maven 中推荐的一种资源文件的组织方式，方便我们在项目中访问和使用这些文件。 public class mybatisTest { public static void main(String[] args) { SqlSession sqlSession=null; try { SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); InputStream is = Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); sqlSession =sqlSessionFactory.openSession(); int count = sqlSession.insert(&quot;car_insert&quot;); System.out.println(count); sqlSession.commit(); } catch (IOException e) { if(sqlSession!=null){ sqlSession.rollback(); } throw new RuntimeException(e); }finally { if(sqlSession!=null){ sqlSession.close(); } } } } Junit介绍 public class MathService{ public int sum(int a, int b){ return a+b; } } public class MathServiceTest{ MathService mathService = new MathService(); @Test public void Testsum(){ int actual = mathService.sum(1,2); int expected = 3; Assert.assertEquals(expected,actual); } } 日志框架 &lt;settings&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot; /&gt; &lt;/settings&gt; Mybatis工具类 public class mybatisUtil { private mybatisUtil(){ } private static SqlSessionFactory sqlSessionFactory; static { try { SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); sqlSessionFactory = sqlSessionFactoryBuilder.build(Resources.getResourceAsStream(&quot;mybatis-config.xml&quot;)); } catch (IOException e) { throw new RuntimeException(e); } } public static SqlSession openSession(){ return sqlSessionFactory.openSession(); } } 三、使用Mybatis完成CRUD &lt;mapper namespace=&quot;com.star.mybatis&quot;&gt; &lt;insert id=&quot;car_insert&quot;&gt; insert into t_car(id,car_num,brand,guide_price,produce_time,car_type) values (null,#{carNum},#{brand},#{guidePrice},#{produceTime},#{carType}) &lt;/insert&gt; &lt;delete id=&quot;car_delete&quot;&gt; delete from t_car where id=#{i} &lt;/delete&gt; &lt;select id=&quot;car_select&quot; resultType=&quot;com.star.mybatis.introduction.pojo.Car&quot;&gt; select * from t_car where id=#{id} &lt;/select&gt; &lt;select id=&quot;car_selectall&quot; resultType=&quot;com.star.mybatis.introduction.pojo.Car&quot;&gt; select * from t_car &lt;/select&gt; &lt;/mapper&gt; public class mybatisTest { @Test public void deletetest(){ SqlSession sqlSession = mybatisUtil.openSession(); int count = sqlSession.delete(&quot;car_delete&quot;,6); System.out.println(count); sqlSession.commit(); sqlSession.close(); } @Test public void testInsert(){ Car car = new Car(null,&quot;001&quot;,&quot;长安&quot;,325.00,&quot;2023-04-03&quot;,&quot;燃油&quot;); SqlSession sqlSession = mybatisUtil.openSession(); int count = sqlSession.insert(&quot;car_insert&quot;,car); System.out.println(count); sqlSession.commit(); sqlSession.close(); } @Test public void testSelect(){ SqlSession sqlSession = mybatisUtil.openSession(); Car car = sqlSession.selectOne(&quot;car_select&quot;,8); System.out.println(car); } @Test public void testSelectAll(){ SqlSession sqlSession = mybatisUtil.openSession(); List&lt;Car&gt; cars = sqlSession.selectList(&quot;car_selectall&quot;); cars.forEach(car -&gt; System.out.println(car)); } } 四、Mybatis核心配置文件详解 五、在WEB中应用Mybatis方法作用域方法作用域是指变量、常量和对象在方法中的可见性和生命周期。在方法内部声明的变量和常量只在方法内部可见，当方法执行结束时，它们也随之消失。对象的作用域可以超出方法，例如一个方法返回一个对象，这个对象在方法外部也可以被使用，直到它被垃圾回收器回收。方法作用域的一个重要特点是，方法内部的变量名或参数名可以与类的成员变量名或参数名相同，但是方法内部的变量或参数会覆盖类的成员变量或参数，直到方法执行结束。应用作用域应用作用域是指对象的生命周期与应用程序的生命周期相同，即在应用程序启动时创建，在应用程序关闭时销毁。在Spring框架中，应用作用域的对象通常使用单例模式创建。在应用作用域下创建的对象可以在整个应用程序中共享，因此在多个地方使用同一个对象可以提高程序的性能。例如，在Web应用程序中，可以在应用作用域下创建一个共享的数据源对象，以便多个线程共享这个对象，避免了频繁创建和销毁数据源对象的开销。请求作用域请求作用域是指在一次 HTTP 请求的处理过程中所创建的对象的作用域。它的生命周期是从请求的开始到响应的结束。在一个 HTTP 请求中，通过 HttpServletRequest 对象可以获取请求作用域，可以将对象存放在请求作用域中，然后在整个请求处理过程中共享这些对象。通常情况下，请求作用域可以用于在不同的页面之间传递数据。为什么SqlSessionFactory的作用域为应用作用域MyBatis中的SqlSessionFactory是一个重量级的对象，主要负责创建和管理SqlSession，其创建过程包含了加载配置文件、解析映射文件、创建数据库连接等操作，因此在创建SqlSessionFactory对象时会耗费较多的资源和时间。而且，一个SqlSessionFactory对象一般情况下只需要创建一次，并在应用生命周期内持续使用，因此将其作用域设置为应用作用域是比较合适的。如果将SqlSessionFactory的作用域设置为方法或请求作用域，那么每次执行操作都需要重新创建和销毁SqlSessionFactory对象，会导致不必要的资源浪费和性能下降。而将其作用域设置为会话作用域也不太合适，因为SqlSessionFactory是线程安全的，多个线程可以共享同一个SqlSessionFactory对象，因此在会话作用域中可能会造成不必要的资源浪费和线程安全问题。为什么SqlSession的作用域为请求作用域在使用 MyBatis 进行数据库操作时，每个 SqlSession 都代表了一次对数据库的操作会话。通常情况下，一个请求需要操作数据库多次，因此需要多次创建 SqlSession 对象。由于 SqlSession 是非线程安全的，每次创建一个 SqlSession 对象实例既需要时间又占用内存，所以为了更好地控制资源的开销，将 SqlSession 的作用域设置为请求作用域是比较合适的选择。将 SqlSession 的作用域设置为请求作用域可以保证每个请求都能获取到一个独立的 SqlSession 实例，避免了线程安全问题和并发访问的冲突。同时，由于每个 SqlSession 对象实例只存在于请求过程中，不会长时间占用内存，能够有效地避免内存泄露的问题，提升了应用程序的稳定性和性能。 六、使用javassist生成类七、MyBatis中接口代理机制及使用 八、Mybatis的小技巧 九、Mybatis参数处理十、Mybatis查询语句专题 十一、动态SQL 十一、Mybatis高级映射及延迟加载 十二、Mybatis缓存 十三、Mybatis逆向工程 十四、Mybatis分页插件 十五、Mybatis注解式开发 十六、Mybatis面试问题Mybatis中的动态SQLMybatis中的动态SQL是指可以根据实际情况生成不同SQL语句的一种特殊语法。通常情况下，动态SQL是用来构建复杂的SQL语句的，例如根据不同条件拼接where语句、根据传入的参数构建不同的查询条件等。Mybatis中提供了一些内置的动态SQL语句，例如if、choose、when、otherwise等，可以根据需要自由组合使用，从而构建出灵活多变的SQL语句。同时，Mybatis也支持使用OGNL表达式来处理动态SQL，可以实现更加灵活的条件组合。掌握动态SQL的使用，可以帮助开发者更加方便地构建出灵活、高效的数据访问逻辑，提升应用的性能和扩展性。Mybatis中的一对多映射在 Mybatis 中，一对多映射是指一个实体类中包含一个集合属性，该集合属性中包含多个与另一个实体类的对应关系，即一个实体类与另一个实体类是一对多的关系。例如，一个班级实体类包含多个学生实体类，那么班级实体类就是一的一方，学生实体类就是多的一方。在 Mybatis 中实现一对多映射，需要使用 Mybatis 提供的 association 和 collection 标签。association 标签用于定义单个对象之间的关系，而 collection 标签则用于定义集合对象之间的关系。具体来说，在映射文件中，需要先定义一的一方的查询语句，并使用 association 标签将多的一方的查询结果映射到一的一方中。然后，再定义多的一方的查询语句，并使用 collection 标签将多的一方的查询结果映射到一的一方的集合属性中。Mybatis中#{}和${}的区别在Mybatis中，#{}和${}都是用来表示参数占位符的，但是它们的作用是不同的。 #{}用于表示一个占位符，Mybatis会将传入的参数自动进行类型转换，然后将转换后的值安全地插入到SQL语句中。这种方式可以有效地防止SQL注入的风险。${}也用于表示一个占位符，但是它不会对传入的参数进行处理，直接将传入的字符串嵌入到SQL语句中。这种方式存在SQL注入的风险，应该尽量避免使用。因此，建议在Mybatis中使用#{}作为参数占位符，以确保系统的安全性。使用 #{} 时，Mybatis 会将 SQL 语句中的 #{} 替换成一个 ? 占位符，并使用 PreparedStatement 来执行 SQL 语句，这样就可以避免 SQL 注入等安全问题。同时，使用 #{} 还可以自动进行类型转换。","categories":[{"name":"Spring","slug":"Spring","permalink":"https://xingxin-99.github.io/categories/Spring/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://xingxin-99.github.io/tags/Mybatis/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://xingxin-99.github.io/categories/Spring/"}]},{"title":"Redis双写一致性","slug":"Redis双写一致性","date":"2023-05-24T12:24:16.000Z","updated":"2023-08-25T07:15:20.198Z","comments":true,"path":"2023/05/24/Redis双写一致性/","link":"","permalink":"https://xingxin-99.github.io/2023/05/24/Redis双写一致性/","excerpt":"","text":"双写一致性是为了保证数据库和缓存中的数据最终一致。 删除缓存还是更新缓存？ 写多读少场景下浪费性能如果采用更新缓存方式的话，那么每对数据库更新一次，就会更新一次缓存。在写多读少的场景下，如果进行了多次更新，但没有一次读取，那中间更新多次缓存的这个过程是没必要的且浪费性能的，因为我们希望读缓存时读的是相对最新的数据。因此目前大多采用类似于懒加载的这种模式，删除缓存后，不使用时不读缓存，只有使用时再去数据库中读取最新的数据。 脏数据问题线程1和线程2都要对数据库中的A数据进行写操作。线程1先执行，在写入数据库要更新缓存之前，线程2来对A进行更新并写入缓存，然后线程1再写入缓存。这导致缓存中是A更新后的数据而不是期望的B更新后的数据，导致最后缓存中出现了脏数据。 先更新数据库还是先删除缓存？ 使用延时双删，为什么要删除两次？为什么第一次要删除？为什么要进行延时？ 延时的目的： 线程B读取数据库，在还未更新缓存时，线程A更新数据库，删除缓存。线程B把读到的数据写入到缓存中，写入的是脏数据。进行延时，等到线程B将脏数据写入到缓存后在进行删除，降低了出现数据不一致性的可能。 主从同步，需要等待从库等待数据更新后再删除缓存，否则读取的还是从库中未更新的数据。 如何判断Reidis中的key删除失败？ Redis的DEL命令用于删除已存在的键，返回值是删除键的数量 redisTemplate.delete(key)，如果删除失败，返回false 如果延时双删，最后的删失败了怎么办？ 失败重试机制 同步重试 异步重试 使用消息队列 订阅binlog日志 使用canal组件订阅binlog日志，当发现binlog中有更新数据的日志时，删除相应的缓存。 定时任务将需要重试的数据写入到重试表中，重试表中有重试次数及数据状态，定时任务每隔一定时间读取重试表中的数据进行重试，如果成功，则将该数据删除，如果不成功则重试次数+1，如果重试次数达到指定值还未更新成功，则重试表中将该记录更新为失败状态。同时考虑是不是由于Redis宕机而导致了更新一直失败，考虑使用Redis集群来提高Redis服务的高可用性。 如何保证缓存与数据库的强一致性？ 如果要保证Redis与数据库的强一致性，可以靠考虑使用Redis的互斥锁实现。当要更新数据时，对要更新的key加上互斥锁，同时开启另一个线程对数据库执行写操作。当写操作执行完毕后释放锁。 如何不要求强一致性，可以怎么做？ 延时双删 Canal组件","categories":[{"name":"Redis","slug":"Redis","permalink":"https://xingxin-99.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://xingxin-99.github.io/tags/Redis/"}],"keywords":[{"name":"Redis","slug":"Redis","permalink":"https://xingxin-99.github.io/categories/Redis/"}]},{"title":"Typora+PicGo+阿里云OSS上传图片","slug":"1","date":"2022-05-25T12:24:16.000Z","updated":"2023-08-25T07:19:07.822Z","comments":true,"path":"2022/05/25/1/","link":"","permalink":"https://xingxin-99.github.io/2022/05/25/1/","excerpt":"","text":"阿里云OSS 登陆进阿里云OSS 创建OSS Bucket 获取AccessKey 保存AccessKey ID与Secret，后面PicGo图床设置会使用到 PicGo 下载PicGo：Releases · Molunerfinn/PicGo (github.com) 选择显示图床 图床设置 验证图片是否能够上传成功 TyporaTypora上传图片设置：文件-&gt;偏好设置-&gt;图像","categories":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}]},{"title":"主题配置","slug":"主题配置","date":"2022-04-25T02:37:16.000Z","updated":"2023-08-25T07:15:09.984Z","comments":true,"path":"2022/04/25/主题配置/","link":"","permalink":"https://xingxin-99.github.io/2022/04/25/主题配置/","excerpt":"","text":"修改对话","categories":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}]},{"title":"搭建博客时遇到的问题","slug":"搭建Blog时遇到的问题","date":"2022-03-24T12:24:16.000Z","updated":"2023-08-25T07:15:14.986Z","comments":true,"path":"2022/03/24/搭建Blog时遇到的问题/","link":"","permalink":"https://xingxin-99.github.io/2022/03/24/搭建Blog时遇到的问题/","excerpt":"","text":"问题：执行hexo d后报错ssh: connect to host github.com port 22: Connection refused，文件不能部署到Github中 解决：换一个端口号 进入.ssh目录，编辑配置文件config cd ~/.ssh vim config 编辑文件内容 Host github.com User git Hostname ssh.github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa Port 443 Host gitlab.com Hostname altssh.gitlab.com User git Port 443 PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa 保存退出，检查是否成功 ssh -T git@github.com 验证hexo d能否成功部署资源到Github，结果成功 参考：Git问题 在分类下添加标签，没有显示创建出分类下的页面 解决： 先生成md文件，在md里添加分类，它会根据这个来生成html页面 创建成功后，再添加至配置文件中 hexo g 生成页面会发现页面已经成功生成 如何修改新的分类下的背景图片？","categories":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}],"tags":[],"keywords":[{"name":"技术","slug":"技术","permalink":"https://xingxin-99.github.io/categories/技术/"}]}]}